{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be5d807",
   "metadata": {},
   "source": [
    "# Quickstart: Agentic retrieval in Azure AI Search using Python\n",
    "\n",
    "This notebook demonstrates the basics of agentic retrieval in Azure AI Search. You create and load a search index, set up a knowledge source and knowledge base, and run queries that use an LLM for query planning and answer synthesis. You also run an optional evaluation to assess the groundedness and relevance of the pipeline.\n",
    "\n",
    "For prerequisites and setup instructions, see [Quickstart: Agentic retrieval using Python](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval?pivots=programming-language-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714a968",
   "metadata": {},
   "source": [
    "## Load connections\n",
    "\n",
    "Before you run this cell, create a virtual environment with `Quickstart-Agentic-Retrieval/requirements.txt` as the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "# Take environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# This notebook uses the following variables from your .env file\n",
    "search_endpoint = os.environ[\"SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "aoai_endpoint = os.environ[\"AOAI_ENDPOINT\"]\n",
    "aoai_embedding_model = os.environ.get(\"AOAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "aoai_embedding_deployment = os.environ.get(\"AOAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "aoai_gpt_model = os.environ.get(\"AOAI_GPT_MODEL\", \"gpt-5-mini\")\n",
    "aoai_gpt_deployment = os.environ.get(\"AOAI_GPT_DEPLOYMENT\", \"gpt-5-mini\")\n",
    "index_name = os.environ.get(\"INDEX_NAME\", \"earth-at-night\")\n",
    "knowledge_source_name = os.environ.get(\"KNOWLEDGE_SOURCE_NAME\", \"earth-knowledge-source\")\n",
    "knowledge_base_name = os.environ.get(\"KNOWLEDGE_BASE_NAME\", \"earth-knowledge-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8a088",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "\n",
    "This step creates an index that contains plain text and vector content. You can use an existing index, but it must meet the criteria for [agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schema requirement is a semantic configuration with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "azure_openai_token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=aoai_endpoint,\n",
    "                    deployment_name=aoai_embedding_deployment,\n",
    "                    model_name=aoai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39874f61",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This notebook uses data from NASA's Earth at Night e-book. The data is retrieved from the [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data) repository on GitHub and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=search_endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb9e5f",
   "metadata": {},
   "source": [
    "## Create a knowledge source\n",
    "\n",
    "This step creates a knowledge source that targets the index you previously created. In the next step, you create a knowledge base that uses the knowledge source to orchestrate agentic retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3415954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndexKnowledgeSource, SearchIndexKnowledgeSourceParameters, SearchIndexFieldReference\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[SearchIndexFieldReference(name=\"id\"), SearchIndexFieldReference(name=\"page_number\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "print(f\"Knowledge source '{knowledge_source_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e0a34",
   "metadata": {},
   "source": [
    "## Create a knowledge base\n",
    "\n",
    "This step creates a knowledge base, which acts as a wrapper for your knowledge source and LLM deployment.\n",
    "\n",
    "`EXTRACTIVE_DATA` is the default modality and returns content from your knowledge sources without generative alteration. However, this quickstart uses the `ANSWER_SYNTHESIS` modality for LLM-generated answers that cite the retrieved content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeBaseAzureOpenAIModel, KnowledgeSourceReference, AzureOpenAIVectorizerParameters, KnowledgeRetrievalOutputMode, KnowledgeRetrievalLowReasoningEffort\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=aoai_endpoint,\n",
    "    deployment_name=aoai_gpt_deployment,\n",
    "    model_name=aoai_gpt_model,\n",
    ")\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=knowledge_base_name,\n",
    "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=knowledge_source_name\n",
    "        )\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
    "    answer_instructions=\"Provide a 2 sentence concise and informative answer based on the retrieved documents.\"\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "print(f\"Knowledge base '{knowledge_base_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d8fbe",
   "metadata": {},
   "source": [
    "## Set up messages\n",
    "\n",
    "Messages are the input for the retrieval route and contain the conversation history. Each message includes a `role` that indicates its origin, such as `system` or `user`, and `content` in natural language. The LLM you use determines which roles are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357268fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "If you don't have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": instructions\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090707f",
   "metadata": {},
   "source": [
    "## Use agentic retrieval to fetch results\n",
    "\n",
    "This step runs the agentic retrieval pipeline to produce a grounded, citation-backed answer. Given the conversation history and retrieval parameters, your knowledge base:\n",
    "\n",
    "1. Analyzes the entire conversation to infer the user's information need.\n",
    "\n",
    "1. Decomposes the compound query into focused subqueries.\n",
    "\n",
    "1. Runs the subqueries concurrently against your knowledge source.\n",
    "\n",
    "1. Uses semantic ranker to rerank and filter the results.\n",
    "\n",
    "1. Synthesizes the top results into a natural-language answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ded26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import KnowledgeBaseRetrievalRequest, KnowledgeBaseMessage, KnowledgeBaseMessageTextContent, SearchIndexKnowledgeSourceParams\n",
    "\n",
    "agent_client = KnowledgeBaseRetrievalClient(endpoint=search_endpoint, knowledge_base_name=knowledge_base_name, credential=credential)\n",
    "query_1 = \"\"\"\n",
    "    Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "    Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": query_1\n",
    "})\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "print(f\"Retrieved content from '{knowledge_base_name}' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fc687",
   "metadata": {},
   "source": [
    "### Review the retrieval response, activity, and results\n",
    "\n",
    "Because your knowledge base is configured for answer synthesis, the retrieval response contains the following values:\n",
    "\n",
    "+ `response_contents`: An LLM-generated answer to the query that cites the retrieved documents.\n",
    "\n",
    "+ `activity_contents`: Detailed planning and execution information, including subqueries, reranking decisions, and intermediate steps.\n",
    "\n",
    "+ `references_contents`: Source documents and chunks that contributed to the answer.\n",
    "\n",
    "**Tip:** Retrieval parameters, such as reranker thresholds and knowledge source parameters, influence how aggressively your agent reranks and which sources it queries. Inspect the activity and references to validate grounding and build traceable citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_contents = []\n",
    "activity_contents = []\n",
    "references_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Build simple string values for response_content, activity_content, and references_content\n",
    "\n",
    "# Responses -> Concatenate text/value fields from all response contents\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response found on 'result'\"\n",
    "\n",
    "response_contents.append(response_content)\n",
    "\n",
    "# Print the three string values\n",
    "print(\"response_content:\\n\", response_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response_content\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity -> JSON string of activity as list of dicts\n",
    "if result.activity:\n",
    "    activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
    "else:\n",
    "    activity_content = \"No activity found on 'result'\"\n",
    "    \n",
    "activity_contents.append(activity_content)\n",
    "print(\"activity_content:\\n\", activity_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172df234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References -> JSON string of references as list of dicts\n",
    "if result.references:\n",
    "    references_content = json.dumps([r.as_dict() for r in result.references], indent=2)\n",
    "else:\n",
    "    references_content = \"No references found on 'result'\"\n",
    "    \n",
    "references_contents.append(references_content)\n",
    "print(\"references_content:\\n\", references_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75386ed1",
   "metadata": {},
   "source": [
    "## Continue the conversation\n",
    "\n",
    "This step continues the conversation with your knowledge base, building upon the previous messages and queries to retrieve relevant information from your knowledge source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da260539",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"How do I find lava at night?\"\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": query_2\n",
    "})\n",
    "\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeBaseMessageTextContent(text=m[\"content\"])]\n",
    "        ) for m in messages if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=knowledge_source_name,\n",
    "            include_references=True,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req)\n",
    "print(f\"Retrieved content from '{knowledge_base_name}' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cba0c",
   "metadata": {},
   "source": [
    "### Review the new retrieval response, activity, and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Build simple string values for response_content, activity_content, and references_content\n",
    "\n",
    "# Responses -> Concatenate text/value fields from all response contents\n",
    "response_parts = []\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        response_parts.append(content.text)\n",
    "response_content = \"\\n\\n\".join(response_parts) if response_parts else \"No response found on 'result'\"\n",
    "\n",
    "response_contents.append(response_content)\n",
    "\n",
    "# Print the three string values\n",
    "print(\"response_content:\\n\", response_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity -> JSON string of activity as list of dicts\n",
    "if result.activity:\n",
    "    activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
    "else:\n",
    "    activity_content = \"No activity found on 'result'\"\n",
    "    \n",
    "activity_contents.append(activity_content)\n",
    "print(\"activity_content:\\n\", activity_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6486c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References -> JSON string of references as list of dicts\n",
    "if result.references:\n",
    "    references_content = json.dumps([r.as_dict() for r in result.references], indent=2)\n",
    "else:\n",
    "    references_content = \"No references found on 'result'\"\n",
    "    \n",
    "references_contents.append(references_content)\n",
    "print(\"references_content:\\n\", references_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98057c5",
   "metadata": {},
   "source": [
    "## Run an evaluation with Microsoft Foundry\n",
    "\n",
    "To evaluate the groundedness and relevance of the pipeline, run an evaluation with Microsoft Foundry. For more detailed guidance, see [Evaluate your generative AI application locally with the Azure AI Evaluation SDK (preview)](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/evaluate-sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88117b3",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "+ The same [Microsoft Foundry project](https://learn.microsoft.com/azure/ai-foundry/how-to/create-projects) you used for agentic retrieval. Set `FOUNDRY_ENDPOINT` to your project endpoint in the `.env` file. You can find this endpoint in the [Microsoft Foundry portal](https://ai.azure.com/).\n",
    "\n",
    "+ The `azure-ai-evaluation` package, which is already installed as part of the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80001db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load connections\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "foundry_endpoint = os.environ[\"FOUNDRY_ENDPOINT\"]\n",
    "aoai_api_version = os.environ[\"AOAI_API_VERSION\"]\n",
    "\n",
    "# Run the evaluation\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration, GroundednessEvaluator, RelevanceEvaluator, evaluate\n",
    "import json\n",
    "\n",
    "evaluation_data = []\n",
    "print(\"Preparing evaluation data...\")\n",
    "for q, r, g in zip([query_1, query_2], references_contents, response_contents):\n",
    "    evaluation_data.append({\n",
    "        \"query\": q,\n",
    "        \"response\": g,\n",
    "        \"context\": r,\n",
    "    })\n",
    "\n",
    "filename = \"evaluation_data.jsonl\"\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    for item in evaluation_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_deployment=aoai_gpt_model\n",
    ")\n",
    "\n",
    "# RAG triad metrics\n",
    "groundedness = GroundednessEvaluator(model_config=model_config)\n",
    "relevance = RelevanceEvaluator(model_config=model_config)\n",
    "\n",
    "print(\"Starting evaluation...\")\n",
    "result = evaluate(\n",
    "    data=filename,\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness,\n",
    "        \"relevance\": relevance,\n",
    "    },\n",
    "    azure_ai_project=foundry_endpoint,\n",
    ")\n",
    "\n",
    "print(\"Evaluation complete.\")\n",
    "studio_url = result.get(\"studio_url\")\n",
    "print(\"For more information, go to the Foundry portal.\") if studio_url else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75777ed2",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need Azure AI Search or Microsoft Foundry, delete the resources from your Azure subscription. You can also start over by deleting individual objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f6fe6",
   "metadata": {},
   "source": [
    "### Delete the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.delete_knowledge_base(knowledge_base_name)\n",
    "print(f\"Knowledge base '{knowledge_base_name}' deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfb289",
   "metadata": {},
   "source": [
    "### Delete the knowledge source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.delete_knowledge_source(knowledge_source=knowledge_source_name)\n",
    "print(f\"Knowledge source '{knowledge_source_name}' deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bfbb1",
   "metadata": {},
   "source": [
    "### Delete the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "index_client.delete_index(index_name)\n",
    "print(f\"Index '{index_name}' deleted successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
