{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# Agentic retrieval using Azure AI Search and Azure AI Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and an Azure AI Agent.\n",
    "\n",
    "In this walkthrough, you will:\n",
    "\n",
    "+ Create an \"earth_at_night\" search index\n",
    "+ Load it with documents from a GitHub URL\n",
    "+ Create a search agent on Azure AI Search that points to an LLM for intelligent query planning\n",
    "+ Create a Foundry agent in Azure AI Foundry to determine when queries are needed\n",
    "+ Create a Azure AI Agent tool (client) to orchestrate all requests\n",
    "+ Start a chat with the agent\n",
    "\n",
    "This notebook is referenced in [Build an agentic retrieval pipeline in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "This exercise differs from the [Agentic Retrieval Quickstart](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval) in how it uses Azure AI Agent to determine whether to retrieve data from the index, and how it uses an agent tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ Azure AI Search, basic tier or higher, in any region that supports semantic ranker.\n",
    "\n",
    "+ Azure OpenAI, and you should have an **Azure AI Developer** role assignment to create a Foundry project.\n",
    "\n",
    "+ An [Azure AI agent and Foundry project](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal), created in the Azure AI Foundry portal, with the basic setup, used for creating the Foundry agent.\n",
    "\n",
    "+ A deployment of a [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) in your Foundry project. This notebook uses gpt-4o-mini. We recommend 100,000 token capacity. You can find capacity and the rate limit in the model deployments list in the Azure AI Foundry portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "Save the `sample.env` file as `.env` and then modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI\n",
    "+ Azure AI Foundry project\n",
    "\n",
    "You can find endpoints for Azure AI Search and Azure OpenAI in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You can find the project connection string in the Azure AI Foundry portal:\n",
    "\n",
    "1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com) and open your project. \n",
    "\n",
    "1. In the **Project details** tile, find and copy the **Project connection string**. \n",
    "\n",
    "   A hypothetical connection string might look like this: `eastus2.api.azureml.ms;00000000-0000-0000-0000-0000000000;rg-my-resource-group-name;my-foundry-project-name`\n",
    "\n",
    "1. Check the authentication type for your Azure OpenAI resource and make sure it uses an API key shared to all projects. Still in **Project details**, expand the **Connected resources** tile to view the authentication type for your Azure OpenAI resource.\n",
    "\n",
    "If you don't have an Azure OpenAI resource in your Foundry project, revisit the model deployment prerequisite. A connection to the resource is created when you deploy a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load Connections\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.10.\n",
    "\n",
    "Once your environment is created, set the endpoints used to run the retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "project_conn_str = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4o-mini\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth_at_night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4o-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-search-agent\")\n",
    "api_version = \"2025-05-01-Preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create search index on Azure AI Search\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This sample uses data from NASA's Earth at Night e-book. It's retrieved from the sample data GitHub repository and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth_at_night'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a search agent on Azure AI Search\n",
    "\n",
    "This steps creates a search agent on Azure AI Search. This agent is a wrapper to a large language model, used for sending queries to an agentic retrieval pipeline. The maximum output size refers to the query response. Setting this value helps you control token usage and how many tokens are sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search agent 'earth-search-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_gpt_deployment,\n",
    "                model_name=azure_openai_gpt_model\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,\n",
    "            default_reranker_threshold=2.5\n",
    "        )\n",
    "    ],\n",
    "    request_limits=KnowledgeAgentRequestLimits(\n",
    "        max_output_size=10000\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Search agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an Azure AI Agent\n",
    "\n",
    "In the Azure AI Foundry, an agent is a smart micro-service that can do RAG. The purpose of this specific agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list', 'data': [{'id': 'asst_sXngVG4fzu0bQJNFmTxzX6h4', 'object': 'assistant', 'created_at': 1746940725, 'name': 'earth-search-agent', 'description': None, 'model': 'gpt-4o-mini', 'instructions': '\\nAn Q&A agent that can answer questions about the Earth at night.\\nSources have a JSON format with a ref_id that must be cited in the answer.\\nIf you do not have the answer, respond with \"I don\\'t know\".\\n', 'tools': [], 'top_p': 1.0, 'temperature': 1.0, 'tool_resources': {}, 'metadata': {}, 'response_format': 'auto'}, {'id': 'asst_lzafrxILzTmhdFaMMEVjuhE8', 'object': 'assistant', 'created_at': 1746940688, 'name': 'earth-search-agent', 'description': None, 'model': 'gpt-4o-mini', 'instructions': '\\nAn Q&A agent that can answer questions about the Earth at night.\\nSources have a JSON format with a ref_id that must be cited in the answer.\\nIf you do not have the answer, respond with \"I don\\'t know\".\\n', 'tools': [], 'top_p': 1.0, 'temperature': 1.0, 'tool_resources': {}, 'metadata': {}, 'response_format': 'auto'}], 'first_id': 'asst_sXngVG4fzu0bQJNFmTxzX6h4', 'last_id': 'asst_lzafrxILzTmhdFaMMEVjuhE8', 'has_more': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(project_conn_str, credential=credential)\n",
    "\n",
    "project_client.agents.list_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa363122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-search-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "import json\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(project_conn_str, credential=credential)\n",
    "\n",
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=agent_model,\n",
    "    name=agent_name,\n",
    "    instructions=instructions\n",
    ")\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a051e",
   "metadata": {},
   "source": [
    "## Add an agentic retrieval tool to AI Agent\n",
    "\n",
    "An end-to-end pipeline needs an orchestration mechanism for coordinating calls to the retriever and agent. The pattern described in this notebook uses a [tool](https://learn.microsoft.com/azure/ai-services/agents/how-to/tools/function-calling) for this task. The tool calls the Azure AI Search knowledge retrieval client and the Azure AI agent, and it drives the conversations with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2ee775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import FunctionTool, ToolSet, ListSortOrder\n",
    "\n",
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "thread = project_client.agents.create_thread()\n",
    "retrieval_results = {}\n",
    "\n",
    "def agentic_retrieval() -> str:\n",
    "    \"\"\"\n",
    "        Searches a NASA e-book about images of Earth at night and other science related facts.\n",
    "        The returned string is in a JSON format that contains the reference id.\n",
    "        Be sure to use the same format in your agent's response\n",
    "    \"\"\"\n",
    "    # Take the last 5 messages in the conversation\n",
    "    messages = project_client.agents.list_messages(thread.id, limit=5, order=ListSortOrder.DESCENDING)\n",
    "    # Reverse the order so the most recent message is last\n",
    "    messages.data.reverse()\n",
    "    retrieval_result = agent_client.knowledge_retrieval.retrieve(\n",
    "        retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "            messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg.content[0].text)]) for msg in messages.data if msg[\"role\"] != \"system\"],\n",
    "            target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Associate the retrieval results with the last message in the conversation\n",
    "    last_message = messages.data[-1]\n",
    "    retrieval_results[last_message.id] = retrieval_result\n",
    "\n",
    "    # Return the grounding response to the agent\n",
    "    return retrieval_result.response[0].content[0].text\n",
    "\n",
    "# Link to AI Agent Service function calling tutorial\n",
    "user_functions = { agentic_retrieval }\n",
    "functions = FunctionTool(user_functions)\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "project_client.agents.enable_auto_function_calls(toolset=toolset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5b621",
   "metadata": {},
   "source": [
    "## Start a chat with the agent\n",
    "\n",
    "During the chat, you use the standard Azure AI agent tool calling APIs.  We send the message with questions, and the agent decides when to retrieve knowledge from your search index using agentic retrieval.\n",
    "\n",
    "The remaining cells take a closer look at output and show how to add another turn to the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fc04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent response: The differences in nighttime brightness between suburban belts and urban cores can be attributed to several factors:\n",
      "\n",
      "1\n",
      " **December Brightening**: Suburban areas tend to have a greater relative increase in brightness during December due to seasonal decorations, festive lighting, and residential activity\n",
      " In contrast, urban cores may have higher absolute light levels due to commercial lighting, but the types of light and their arrangement can lead to a less pronounced increase compared to the festive displays in suburban settings\n",
      " Urban centers often focus on commercial light sources that may not display the same wide variability in illumination as residential areas do during holidays (Source: ref_id 0)\n",
      "\n",
      "\n",
      "2\n",
      " **Visibility of Phoenix's Nighttime Grid**: The sharp visibility of the Phoenix nighttime street grid from space can be attributed to its planned urban layout, which features a grid pattern of streets and blocks that are well-illuminated\n",
      " This grid is a result of urban design that promotes easy navigation and access, leading to concentrated bright spots along major streets and intersections\n",
      " In contrast, the interstate stretches in the Midwest tend to connect larger rural areas with fewer lighted nodes due to the sparser population and fewer urban developments, making those areas appear relatively dim from space (Source: ref_id 1)\n",
      "\n",
      "\n",
      "The differences in light patterns between urban and suburban areas, alongside the planned layouts of cities like Phoenix, significantly influence how they are perceived in nighttime satellite imagery\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id, toolset=toolset)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "output = project_client.agents.list_messages(thread_id=thread.id).get_last_text_message_by_role(\"assistant\").text.value\n",
    "\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88be35",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n",
    "\n",
    "Each retrieval response from Azure AI Search includes the unified string (grounding data from search search results), the query plan, and  reference data showing which chunks of source document contributed content to the unified string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b90fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval activity\n",
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"type\": \"ModelQueryPlanning\",\n",
      "    \"input_tokens\": 1265,\n",
      "    \"output_tokens\": 277\n",
      "  },\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"suburban belts December brightening urban cores comparison\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:22:45.368Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 350\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"Phoenix nighttime street grid visibility from space\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:22:45.682Z\",\n",
      "    \"count\": 2,\n",
      "    \"elapsed_ms\": 304\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"interstate visibility from space midwestern cities\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:22:45.977Z\",\n",
      "    \"count\": 2,\n",
      "    \"elapsed_ms\": 291\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"type\": \"AzureSearchSemanticRanker\",\n",
      "    \"input_tokens\": 74224\n",
      "  }\n",
      "]\n",
      "Retrieval results\n",
      "[\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"2\",\n",
      "    \"activity_source\": 2,\n",
      "    \"doc_key\": \"earth_at_night_508_page_104_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"0\",\n",
      "    \"activity_source\": 2,\n",
      "    \"doc_key\": \"earth_at_night_508_page_105_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"3\",\n",
      "    \"activity_source\": 3,\n",
      "    \"doc_key\": \"earth_at_night_508_page_125_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"1\",\n",
      "    \"activity_source\": 3,\n",
      "    \"doc_key\": \"earth_at_night_508_page_124_verbalized\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retrieval_result = retrieval_results.get(message.id)\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bfb9f",
   "metadata": {},
   "source": [
    "## Continue the conversation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9478191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent response: To find lava at night, you can take advantage of various natural and technological methods:\n",
      "\n",
      "1\n",
      " **Natural Glow**: Active lava flows produce a significant glow, which can be visible from a distance at night\n",
      " Under good visibility conditions, the bright red-orange light of flowing lava can be seen against the darker landscape\n",
      " Observing this from higher vantage points or from areas with minimal light pollution can enhance visibility\n",
      "\n",
      "\n",
      "2\n",
      " **Satellite Imagery**: During nighttime, satellites equipped with capabilities like the VIIRS (Visible Infrared Imaging Radiometer Suite) can capture images of areas with volcanic activity\n",
      " These images show the glow of active lava flows clearly against the background, which highlights volcanic eruptions and their effects\n",
      " For example, images of Mount Etna and Kilauea have shown their lava flows brightly illuminated at night (Source: ref_id 1, ref_id 4)\n",
      "\n",
      "\n",
      "3\n",
      " **Infrared Imaging**: Thermal imaging can also assist in identifying hot lava spots\n",
      " This method utilizes infrared sensors to detect heat emitted by lava flows, making it effective even in darkness\n",
      " Satellites and drones equipped with thermal cameras can provide detailed imagery showing lava flows and their progression\n",
      "\n",
      "\n",
      "4\n",
      " **Safety Considerations**: While observing lava, always prioritize safety\n",
      " Ensure you are at a safe distance from volcanic activity and follow any guidance from local authorities regarding volcanic eruptions\n",
      "\n",
      "\n",
      "In summary, you can find lava at night by looking for its natural glow, using satellite imagery and infrared sensors, and ensuring a safe viewing approach\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How do I find lava at night?\"\n",
    ")\n",
    "\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id, toolset=toolset)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "output = project_client.agents.list_messages(thread_id=thread.id).get_last_text_message_by_role(\"assistant\").text.value\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366ed37",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c063c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval activity\n",
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"type\": \"ModelQueryPlanning\",\n",
      "    \"input_tokens\": 1565,\n",
      "    \"output_tokens\": 299\n",
      "  },\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"how to locate lava flows at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:23:07.269Z\",\n",
      "    \"count\": 6,\n",
      "    \"elapsed_ms\": 376\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"best tools for viewing lava at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:23:07.575Z\",\n",
      "    \"count\": 1,\n",
      "    \"elapsed_ms\": 293\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"safety tips for exploring lava at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-13T22:23:07.857Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 281\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"type\": \"AzureSearchSemanticRanker\",\n",
      "    \"input_tokens\": 70920\n",
      "  }\n",
      "]\n",
      "Retrieval results\n",
      "[\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"5\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_60_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"4\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_64_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"3\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_46_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"2\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_66_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"1\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_65_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"0\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_44_verbalized\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "retrieval_result = retrieval_results.get(message.id)\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04661708",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need the resources, be sure to delete them from your Azure subscription.  You can also delete individual objects to start over.\n",
    "\n",
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search agent 'earth-search-agent' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_agent(agent_name)\n",
    "print(f\"Search agent '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ea545",
   "metadata": {},
   "source": [
    "### Delete the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9895f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
