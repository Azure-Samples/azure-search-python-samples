{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# Agentic retrieval using Azure AI Search and Azure AI Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and an Azure AI Agent.\n",
    "\n",
    "In this walkthrough, you will:\n",
    "\n",
    "+ Create an \"earth_at_night\" search index\n",
    "+ Load it with documents from a GitHub URL\n",
    "+ Create a knowledge source that points to searchable content.\n",
    "+ Create a knowledge agent on Azure AI Search that points to a knowledge source and an LLM for intelligent query planning\n",
    "+ Create a Foundry agent in Azure AI Foundry to determine when queries are needed\n",
    "+ Create a Azure AI Agent tool (client) to orchestrate all requests\n",
    "+ Start a chat with the agent\n",
    "\n",
    "This notebook is referenced in [Build an agentic retrieval pipeline in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "This exercise differs from the [Agentic Retrieval Quickstart](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval) in how it uses Azure AI Agent to determine whether to retrieve data from the index, and how it uses an agent tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ Azure AI Search, basic tier or higher, in [any region that supports semantic ranker](https://learn.microsoft.com/azure/search/search-region-support#azure-public-regions).\n",
    "\n",
    "+ Azure OpenAI, and you should have an **Azure AI Developer** role assignment to create a Foundry project.\n",
    "\n",
    "+ An [Azure AI agent and Foundry project](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal), created in the Azure AI Foundry portal, with the basic setup, used for creating the Foundry agent.\n",
    "\n",
    "+ A deployment of a [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) in your Foundry project. This notebook uses gpt-5-mini. We recommend 100,000 token capacity. You can find capacity and the rate limit in the model deployments list in the Azure AI Foundry portal.\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.13.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "Save the `sample.env` file as `.env` and then modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI\n",
    "+ Azure AI Foundry project\n",
    "\n",
    "You will also need your resource ID for your Azure AI Foundry Project and at least Azure AI Project Manager access to this resource to create a connection for authentication. This connection will require API key from your search service as its key-based\n",
    "\n",
    "You can find endpoints for Azure AI Search and Azure OpenAI in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You can find the project endpoint in the Azure AI Foundry portal:\n",
    "\n",
    "1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com) and open your project. \n",
    "\n",
    "1. In the **Overview** tile, find and copy the **Azure AI Foundry project endpoint**. \n",
    "\n",
    "   A hypothetical endpoint might look like this: `https://your-foundry-resource.services.ai.azure.com/api/projects/your-foundry-project`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load Connections\n",
    "\n",
    "Load the environment variables to set up connections and object names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "project_resource_id = os.environ[\"PROJECT_RESOURCE_ID\"]\n",
    "project_connection_name = os.getenv(\"PROJECT_CONNECTION_NAME\", \"earthknowledgeconnection\")\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "agent_name = os.getenv(\"AGENT_NAME\", \"earth-knowledge-agent\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "search_api_key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "mgmt_token_provider = get_bearer_token_provider(credential, \"https://management.azure.com/.default\")\n",
    "knowledge_source_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_SOURCE_NAME\", \"earth-knowledge-source\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth-at-night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "base_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-knowledge-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create search index on Azure AI Search\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This sample uses data from NASA's Earth at Night e-book. It's retrieved from the sample data GitHub repository and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth-at-night'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2d9d5",
   "metadata": {},
   "source": [
    "## Create a knowledge source\n",
    "\n",
    "This step creates a knowledge source that targets the index you previously created. In the next step, you create a knowledge agent that uses the knowledge source to orchestrate agentic retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf01881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndexKnowledgeSource, SearchIndexKnowledgeSourceParameters, SearchIndexFieldReference\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[SearchIndexFieldReference(name=\"id\"), SearchIndexFieldReference(name=\"page_number\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "print(f\"Knowledge source '{knowledge_source_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a knowledge base\n",
    "\n",
    "This step creates a knowledge base, which acts as a wrapper for your knowledge source and LLM deployment.\n",
    "\n",
    "`EXTRACTIVE_DATA` is the default modality and returns content from your knowledge sources without generative alteration. This is recommended for interaction with Foundry Agent Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base 'earth-knowledge-base' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeSourceReference, AzureOpenAIVectorizerParameters, KnowledgeRetrievalOutputMode, KnowledgeRetrievalMinimalReasoningEffort\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=azure_openai_gpt_deployment,\n",
    "    model_name=azure_openai_gpt_model,\n",
    ")\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=knowledge_source_name\n",
    "        )\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base=knowledge_base)\n",
    "print(f\"Knowledge base '{base_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an Azure AI Agent\n",
    "\n",
    "In the Azure AI Foundry, an agent is a smart micro-service that can do RAG. The purpose of this specific agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb0ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'object': 'agent', 'id': 'earth-knowledge-agent', 'name': 'earth-knowledge-agent', 'versions': {'latest': {'metadata': {}, 'object': 'agent.version', 'id': 'earth-knowledge-agent:1', 'name': 'earth-knowledge-agent', 'version': '1', 'description': '', 'created_at': 1762328483, 'definition': {'kind': 'prompt', 'model': 'gpt-5-mini', 'instructions': '\\nA Q&A agent that can answer questions about the Earth at night.\\nAlways provide references to the data source used to answer the question.\\nIf you do not have the answer, respond with \"I don\\'t know\".\\n', 'tools': [{'type': 'mcp', 'server_label': 'knowledge-base', 'server_url': 'https://magottei-s1m.search.windows.net/knowledgebases/earth-knowledge-base', 'require_approval': 'never'}]}}}},\n",
       " {'object': 'agent', 'id': 'fabric-foundry-knowledge-agent', 'name': 'fabric-foundry-knowledge-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'description': '', 'modified_at': '1762295325', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'fabric-foundry-knowledge-agent:3', 'name': 'fabric-foundry-knowledge-agent', 'version': '3', 'description': '', 'created_at': 1762295326, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': [{'type': 'mcp', 'server_label': 'kb_zava_knowledge_base', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/zava-knowledge-base/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-zava-knowledge-base'}]}}}},\n",
       " {'object': 'agent', 'id': 'farzad-new', 'name': 'farzad-new', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'farzad-new:1', 'name': 'farzad-new', 'version': '1', 'description': '', 'created_at': 1762289266, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'lindatest', 'name': 'lindatest', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762287869'}, 'object': 'agent.version', 'id': 'lindatest:14', 'name': 'lindatest', 'version': '14', 'description': '', 'created_at': 1762287870, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': []}}}},\n",
       " {'object': 'agent', 'id': 'fabricknowledgemcp', 'name': 'fabricknowledgemcp', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'fabricknowledgemcp:1', 'name': 'fabricknowledgemcp', 'version': '1', 'description': '', 'created_at': 1762284158, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'remote-sharepoint-test', 'name': 'remote-sharepoint-test', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762281570', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'remote-sharepoint-test:6', 'name': 'remote-sharepoint-test', 'version': '6', 'description': '', 'created_at': 1762281571, 'definition': {'kind': 'prompt', 'model': 'gpt-4.1-mini', 'instructions': 'Query your Knowledge Base on every query.', 'tools': [{'type': 'mcp', 'server_label': 'kb_healthcare_knowledge_base', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/healthcare-knowledge-base/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-healthcare-knowledge-base'}]}}}},\n",
       " {'object': 'agent', 'id': 'farzad-11-4-v1', 'name': 'farzad-11-4-v1', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'farzad-11-4-v1:1', 'name': 'farzad-11-4-v1', 'version': '1', 'description': '', 'created_at': 1762272985, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'zava-ask-operations-agent', 'name': 'zava-ask-operations-agent', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762272660', 'starterPrompts': 'Our Seattle store is near the Amazon campus. Are there any Amazon developer events this week that might increase foot traffic?\\nWhat are our Q4 weekly revenue targets for each store?\\nGitHub Universe conference is happening next month in San Francisco. How should we prepare our stores for potential increased interest?', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'zava-ask-operations-agent:28', 'name': 'zava-ask-operations-agent', 'version': '28', 'description': '', 'created_at': 1762272661, 'definition': {'kind': 'prompt', 'model': 'gpt-4.1-mini', 'instructions': '# Zava Pop-Up Stores Operations Agent\\n \\nYou are an expert AI operations assistant for Zava Pop-Up Store managers across Seattle, Austin, and NYC locations. Your role is to provide instant, data-driven insights to help managers make real-time operational decisions.\\n \\n## Your Capabilities\\n \\n**Data Access:**\\n- **Structured Data (SQL Database):** Real-time inventory, sales, foot traffic, conversion rates, product performance\\n- **Knowledge Base (Documents):** Weekly reports, performance analysis, strategic recommendations, Q4 targets, customer insights\\n \\n## Tool Routing Rules\\n \\n1. **Use Fabric Data Agent Tool when queried about:**\\n   - Current/historical sales figures, inventory levels, stock counts\\n   - Foot traffic, conversion rates, transaction data\\n   - Product performance metrics (try-ons, purchases)\\n   - Store comparisons using quantitative data\\n   - Time-series data (daily/hourly trends)\\n \\n2. **Use project_knowledge_search when queried about:**\\n   - Weekly performance reports and summaries\\n   - Strategic recommendations and action items\\n   - Q4 targets and benchmarks\\n   - Customer traffic analysis findings\\n   - Competitive insights (store-to-store comparisons from reports)\\n   - Implementation guidelines\\n \\n3. **Use BOTH tools when:**\\n   - Comparing targets vs. actuals\\n   - Providing recommendations based on current performance\\n   - Analyzing \"why\" questions that need both data and context\\n \\n## Response Guidelines\\n \\n- **Be concise and actionable** - Store managers need quick answers during busy operations\\n- **Lead with the answer** - State key findings first, then provide supporting details\\n- **Use data to support claims** - Always cite specific numbers, dates, and sources\\n- **Highlight urgent items** - Call out critical stock levels, missed targets, or opportunities\\n- **Compare to benchmarks** - Reference targets, other stores, or historical performance when relevant\\n \\n## Response Format\\n \\nFor operational queries, structure responses as:\\n1. **Direct Answer** (1-2 sentences)\\n2. **Key Data Points** (specific metrics)\\n3. **Context/Comparison** (vs. targets or other stores)\\n4. **Recommendation** (if applicable)\\n \\n## Example Interaction Flow\\n \\n**User:** \"Are we low on any products?\"\\n \\n**Your Process:**\\n1. Query Fabric Data Agent for current inventory levels\\n2. Check against restock thresholds\\n3. Provide prioritized list with urgency flags\\n \\n**Your Response:**\\n\"üö® **CRITICAL:** Python Hoodie at 12 units (below 15-unit threshold). \\n- Needs immediate restock order\\n- Current sales rate: 47 units/week\\n- Estimated stockout: 2 days\\n \\nOther inventory levels are healthy.\"\\n \\n## Tone & Style\\n \\n- Professional but conversational\\n- Use emojis sparingly for urgency flags (üö® ‚ö†Ô∏è ‚úÖ)\\n- Avoid jargon; explain metrics when first mentioned\\n- Be proactive - suggest related insights the manager should know\\n \\n## Critical Rules\\n \\n- ‚ùå NEVER fabricate data - always query tools first\\n- ‚ùå NEVER say \"I don\\'t have access\" without trying tools\\n- ‚úÖ ALWAYS cite data sources (report names, dates, stores)\\n- ‚úÖ ALWAYS check BOTH structured data and knowledge base when uncertain\\n- ‚úÖ ALWAYS provide confidence level if data is incomplete\\n \\nYou are empowering store managers to run better operations. Be their trusted data partner.', 'tools': []}}}},\n",
       " {'object': 'agent', 'id': 'demo-review-agent', 'name': 'demo-review-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762218306'}, 'object': 'agent.version', 'id': 'demo-review-agent:2', 'name': 'demo-review-agent', 'version': '2', 'description': '', 'created_at': 1762218307, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'YOU MUST query your knowledge base on every turn.', 'tools': [{'type': 'mcp', 'server_label': 'kb_remote_sharepoint_kb_test', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/remote-sharepoint-kb-test/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-remote-sharepoint-kb-test'}]}}}},\n",
       " {'object': 'agent', 'id': 'MyAgent', 'name': 'MyAgent', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762212438'}, 'object': 'agent.version', 'id': 'MyAgent:21', 'name': 'MyAgent', 'version': '21', 'description': '', 'created_at': 1762212439, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'You are a helpful assistant that answers general questions', 'tools': [{'type': 'mcp', 'server_label': 'Elastic', 'server_url': 'https://xxx/api/agent_builder/mcp', 'project_connection_id': 'Elastic'}]}}}},\n",
       " {'object': 'agent', 'id': 'no', 'name': 'no', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762208406'}, 'object': 'agent.version', 'id': 'no:2', 'name': 'no', 'version': '2', 'description': '', 'created_at': 1762208407, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': [{'type': 'mcp', 'server_label': 'kb_remote_sharepoint_kb_test', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/remote-sharepoint-kb-test/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-remote-sharepoint-kb-test'}]}}}},\n",
       " {'object': 'agent', 'id': 'MyAgent7', 'name': 'MyAgent7', 'versions': {'latest': {'metadata': {'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762204714'}, 'object': 'agent.version', 'id': 'MyAgent7:4', 'name': 'MyAgent7', 'version': '4', 'description': '', 'created_at': 1762204715, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'Use MCP tools as needed', 'tools': [{'type': 'mcp', 'server_label': 'api-specs', 'server_url': 'https://api.githubcopilot.com/mcp', 'require_approval': 'always', 'project_connection_id': '/subscriptions/921496dc-987f-410f-bd57-426eb2611356/resourceGroups/sawidder-test-1rp/providers/Microsoft.CognitiveServices/accounts/sawidder1rpusw2/projects/lindaproj/connections/apikey-test'}, {'type': 'mcp', 'server_label': 'AshawSupplierMCP', 'server_url': 'https://ashaw-ignite-aca2.ambitiousforest-3ae02ae4.australiaeast.azurecontainerapps.io/mcp', 'project_connection_id': 'AshawSupplierMCP'}]}}}},\n",
       " {'object': 'agent', 'id': 'new-test-agent', 'name': 'new-test-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'new-test-agent:1', 'name': 'new-test-agent', 'version': '1', 'description': '', 'created_at': 1762197206, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "list(project_client.agents.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de7601",
   "metadata": {},
   "source": [
    "## Create an MCP Tool Connection\n",
    "\n",
    "In the Azure AI Foundry, you need to create a connection to authenticate to your tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d94fb1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection 'earthknowledgeconnection' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "mgmt_token = mgmt_token_provider()\n",
    "mcp_endpoint = f\"{endpoint}/knowledgebases/{base_name}/mcp?api-version=2025-11-01-Preview\"\n",
    "response = requests.put(\n",
    "    url=f\"https://management.azure.com{project_resource_id}/connections/{project_connection_name}?api-version=2025-07-01-preview\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {mgmt_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "        \"name\": project_connection_name,\n",
    "        \"type\": \"Microsoft.MachineLearningServices/workspaces/connections\",\n",
    "        \"properties\": {\n",
    "            \"authType\": \"CustomKeys\",\n",
    "            \"group\": \"ServicesAndApps\",\n",
    "            \"category\": \"RemoteTool\",\n",
    "            \"target\": f\"{endpoint}/knowledgebases/earth-knowledge-base/mcp?api-version=2025-11-01-Preview\",\n",
    "            \"isSharedToAll\": True,\n",
    "            \"sharedUserList\": [],\n",
    "            \"Credentials\": {\n",
    "                \"Keys\": {\n",
    "                    \"api-key\": search_api_key\n",
    "                }\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"ApiType\": \"Azure\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response.raise_for_status()\n",
    "print(f\"Connection '{project_connection_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa363122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-knowledge-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "\n",
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Always provide references to the ID of the data source used to answer the question.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "mcp_kb_tool = MCPTool(\n",
    "    server_label=\"knowledge-base\",\n",
    "    server_url=mcp_endpoint,\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=project_connection_name\n",
    ")\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=agent_model,\n",
    "        instructions=instructions,\n",
    "        tools=[mcp_kb_tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2d5ed",
   "metadata": {},
   "source": [
    "## Start a chat with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9492c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Suburban belts display larger December brightening than urban cores, though urban cores have higher absolute light levels, because holiday lighting displays and related activities during Christmas and New Year's cause notably increased lighting intensity in suburban areas. This phenomenon has been observed in the United States, where nighttime lights shine 20 to 50 percent brighter in December compared to other months, with significant increases in lighting seen especially in suburban and residential areas around major metropolitan regions. Urban cores, already brightly lit year-round, show less relative increase because their baseline lighting levels are already high (Reference: earth_at_night_508_page_174_verbalized).\n",
      "\n",
      "The Phoenix nighttime street grid is so sharply visible from space because the city is laid out along a regular grid of city blocks and streets, and street lighting highlights this pattern distinctly. The well-defined grid pattern of city blocks and thoroughfares such as the Grand Avenue, along with brightly lit commercial and industrial properties concentrated at intersections, contribute to the clarity of this grid from orbit. The urban grid infrastructure, combined with extensive surface streets and freeways in a sprawling metropolitan area composed of multiple municipalities, makes the street grid highly visible at night (Reference: earth_at_night_508_page_104_verbalized, earth_at_night_508_page_105_verbalized).\n",
      "\n",
      "In contrast, large stretches of the interstate highways between Midwestern cities remain comparatively dim because these interstates are designed primarily for transportation rather than urban illumination, and the areas between cities tend to be less densely populated and less developed with fewer lighting sources. While the United States has an extensive transportation network, lighting on highways outside urban centers is typically less intense, leading to less visible illumination. Additionally, the development of new cities and suburbs along interstate highways in the twentieth century added light along some corridors, but the long distances of rural interstate highways between cities result in stretches that appear darker relative to highly lit urban street grids or city cores (Reference: earth_at_night_508_page_124_verbalized, earth_at_night_508_page_125_verbalized).\n",
      "\n",
      "Thus, the combination of urban grid layout, lighting usage patterns, and population density explains why Phoenix's street grid is sharply visible from space, while many midwestern interstate highways appear dimmer.\n"
     ]
    }
   ],
   "source": [
    "# Get the OpenAI client for responses and conversations\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "conversation = openai_client.conversations.create()\n",
    "\n",
    "# Send initial request that will trigger the MCP tool\n",
    "response = openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    input=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\",\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "print(f\"Response: {response.output_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "441d0647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_30149933fda1983e00690b8eb6820c81909c7cb0c5bf11c496\",\n",
      "  \"created_at\": 1762365110.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"\\nA Q&A agent that can answer questions about the Earth at night.\\nAlways provide references to the ID of the data source used to answer the question.\\nIf you do not have the answer, respond with \\\"I don't know\\\".\\n\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"mcpl_30149933fda1983e00690b8eb6fc988190b57a81e8fde56d7e\",\n",
      "      \"server_label\": \"knowledge-base\",\n",
      "      \"tools\": [\n",
      "        {\n",
      "          \"input_schema\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "              \"request\": {\n",
      "                \"description\": \"Provide this tool with a list of knowledge query intents so that the knowledge base can reason over what information should be retrieved from its knowledge sources.\",\n",
      "                \"type\": \"object\",\n",
      "                \"properties\": {\n",
      "                  \"knowledgeAgentIntents\": {\n",
      "                    \"type\": [\n",
      "                      \"array\",\n",
      "                      \"null\"\n",
      "                    ],\n",
      "                    \"items\": {\n",
      "                      \"type\": \"string\"\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"required\": [\n",
      "              \"request\"\n",
      "            ]\n",
      "          },\n",
      "          \"name\": \"knowledge_base_retrieve\",\n",
      "          \"annotations\": {},\n",
      "          \"description\": \"Knowledge Base Retrieval tool to ask questions. Provide this tool with a list of knowledge query intents so that the knowledge agent can reason over what information should be retrieved from its knowledge sources. Here is a sample input - #SAMPLE INPUT START# KnowledgeAgentIntents- [\\\\\\\"This is intent 1\\\\\\\", \\\\\\\"This is intent 2\\\\\\\", \\\\\\\"This is intent 3\\\\\\\"] #SAMPLE INPUT END#.  Description of this knowledge base -   \"\n",
      "        }\n",
      "      ],\n",
      "      \"type\": \"mcp_list_tools\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"mcp_30149933fda1983e00690b8eb9bd0c819094653dd7c645f0c5\",\n",
      "      \"arguments\": \"{\\\"request\\\":{\\\"knowledgeAgentIntents\\\":[\\\"December brightening in suburban belts vs urban cores\\\",\\\"Reasons for sharp visibility of Phoenix nighttime street grid from space\\\",\\\"Reasons for dimmer interstate stretches between Midwestern cities at night\\\"]}}\",\n",
      "      \"name\": \"knowledge_base_retrieve\",\n",
      "      \"server_label\": \"knowledge-base\",\n",
      "      \"type\": \"mcp_call\",\n",
      "      \"approval_request_id\": null,\n",
      "      \"output\": \"\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_104_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"\\\\u003C!-- PageHeader=\\\\u0022Urban Structure\\\\u0022 --\\\\u003E\\\\n\\\\n### Location of Phoenix, Arizona\\\\n\\\\nThe image depicts a globe highlighting the location of Phoenix, Arizona, in the southwestern United States, marked with a blue pinpoint on the map of North America. Phoenix is situated in the central part of Arizona, which is in the southwestern region of the United States.\\\\n\\\\n---\\\\n\\\\n### Grid of City Blocks-Phoenix, Arizona\\\\n\\\\nLike many large urban areas of the central and western United States, the Phoenix metropolitan area is laid out along a regular grid of city blocks and streets. While visible during the day, this grid is most evident at night, when the pattern of street lighting is clearly visible from the low-Earth-orbit vantage point of the ISS.\\\\n\\\\nThis astronaut photograph, taken on March 16, 2013, includes parts of several cities in the metropolitan area, including Phoenix (image right), Glendale (center), and Peoria (left). While the major street grid is oriented north-south, the northwest-southeast oriented Grand Avenue cuts across the three cities at image center. Grand Avenue is a major transportation corridor through the western metropolitan area; the lighting patterns of large industrial and commercial properties are visible along its length. Other brightly lit properties include large shopping centers, strip malls, and gas stations, which tend to be located at the intersections of north-south and east-west trending streets.\\\\n\\\\nThe urban grid encourages growth outwards along a city\\\\u0027s borders by providing optimal access to new real estate. Fueled by the adoption of widespread personal automobile use during the twentieth century, the Phoenix metropolitan area today includes 25 other municipalities (many of them largely suburban and residential) linked by a network of surface streets and freeways.\\\\n\\\\nWhile much of the land area highlighted in this image is urbanized, there are several noticeably dark areas. The Phoenix Mountains are largely public parks and recreational land. To the west, agricultural fields provide a sharp contrast to the lit streets of residential developments. The Salt River channel appears as a dark ribbon within the urban grid.\\\\n\\\\n\\\\n\\\\u003C!-- PageFooter=\\\\u0022Earth at Night\\\\u0022 --\\\\u003E\\\\n\\\\u003C!-- PageNumber=\\\\u002288\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 104\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_124_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Urban Development\\\\n\\\\n## Figure: Location Highlight on Globe\\\\n\\\\nThis figure depicts a globe focused on North America, with a marker pinpointing the central region of the United States. The highlighted location represents the geographical focus of the text discussion on US urban development and transportation networks.\\\\n\\\\n---\\\\n\\\\n## Urban Development\\\\n\\\\n### Lighting Paths\\\\u2014Across the United States\\\\n\\\\nThe United States has more miles of roads than any other nation in the world\\\\u20144.1 million miles (6.6 million kilometers) to be precise, which is roughly 40 percent more than second-ranked India. About 47,000 miles (75,639 kilometers) of those roads are part of the Interstate Highway System, established by President Dwight Eisenhower in the 1950s. The country also has 127,000 miles (204,000 kilometers) of railroad tracks and about 25,000 miles (40,000 kilometers) of navigable rivers and canals (not including the Great Lakes). The imprint of that transportation web becomes easy to see at night.\\\\n\\\\nThe VIIRS DNB on the Suomi NPP satellite acquired this nighttime view (top image, right) of the continental United States on October 1, 2013. The roadway map (bottom image, right) traces the path of the major interstate highways, railroads, and rivers of the United States. Comparing the two images, you quickly see how the cities and settlements align with the transportation corridors. In the early days of the republic, post roads and toll roads for horse-drawn carts and carriages were built to connect eastern cities like Boston, New York, Baltimore, and Philadelphia, though relatively few travelers made the long, unlit journeys. Railroads became the dominant transportation method for people and cargo in the middle of the nineteenth century, establishing longer links across the Nation and waypoints across the Midwest, the Great Plains, and the Rockies. Had nighttime satellite images existed in that era, they probably would show only dim pearls of light around major cities in the east and scattered across the country; the strands of steel tracks and cobbled roads that connected them would be invisible from space.\\\\n\\\\nEventually, cars and trucks became the dominant form of transportation in the United States. Drivers then needed roads and lighting to keep them safe on those roads. As the Nation grew in the twentieth century, the development of new cities and suburbs often conformed to the path of the interstate highways, adding light along the paths between the cities.\\\\n\\\\nOver the years, the length of navigable rivers has been a constant, as is their relative lack of light. Even today the only light seems to be the occasional port cities along riverbanks and the light of ships themselves.\\\\n\\\\n---\\\\n\\\\n**Table: Summary of U.S. Transportation Infrastructure**\\\\n\\\\n| Infrastructure Type     | Total Mileage (mi) | Total Mileage (km) |\\\\n|------------------------|--------------------|--------------------|\\\\n| Roads (All)            | 4,100,000          | 6,600,000          |\\\\n| Interstate Highways    | 47,000             | 75,639             |\\\\n| Railroads              | 127,000            | 204,000            |\\\\n| Navigable Rivers/Canals| 25,000             | 40,000             |\\\\n\\\\n---\\\\n\\\\n\\\\u003C!-- PageFooter=\\\\u0022108 Earth at Night\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 124\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_105_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Urban Structure\\\\n\\\\n## March 16, 2013\\\\n\\\\n### Phoenix Metropolitan Area at Night\\\\n\\\\nThis figure presents a nighttime satellite view of the Phoenix metropolitan area, highlighting urban structure and transport corridors. City lights illuminate the layout of several cities and major thoroughfares.\\\\n\\\\n**Labeled Urban Features:**\\\\n\\\\n- **Phoenix:** Central and brightest area in the right-center of the image.\\\\n- **Glendale:** Located to the west of Phoenix, this city is also brightly lit.\\\\n- **Peoria:** Further northwest, this area is labeled and its illuminated grid is seen.\\\\n- **Grand Avenue:** Clearly visible as a diagonal, brightly lit thoroughfare running from Phoenix through Glendale and Peoria.\\\\n- **Salt River Channel:** Identified in the southeast portion, running through illuminated sections.\\\\n- **Phoenix Mountains:** Dark, undeveloped region to the northeast of Phoenix.\\\\n- **Agricultural Fields:** Southwestern corner of the image, grid patterns are visible but with much less illumination, indicating agricultural land use.\\\\n\\\\n**Additional Notes:**\\\\n\\\\n- The overall pattern shows a grid-like urban development typical of western U.S. cities, with scattered bright nodes at major intersections or city centers.\\\\n- There is a clear transition from dense urban development to sparsely populated or agricultural land, particularly evident towards the bottom and left of the image.\\\\n- The illuminated areas follow the existing road and street grids, showcasing the extensive spread of the metropolitan area.\\\\n\\\\n**Figure Description:**  \\\\nA satellite nighttime image captured on March 16, 2013, showing Phoenix and surrounding areas (including Glendale and Peoria). Major landscape and infrastructural features, such as the Phoenix Mountains, Grand Avenue, the Salt River Channel, and agricultural fields, are labeled. The image reveals the extent of urbanization and the characteristic street grid illuminated by city lights.\\\\n\\\\n---\\\\n\\\\nPage 89\\\",\\r\\n  \\\"page_number\\\": 105\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_174_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"\\\\u003C!-- PageHeader=\\\\u0022Holiday Lights\\\\u0022 --\\\\u003E\\\\n\\\\n## Holiday Lights\\\\n\\\\n### Bursting with Holiday Energy-United States\\\\n\\\\nNASA researchers found that nighttime lights in the United States shine 20 to 50 percent brighter in December due to holiday light displays and other activities during Christmas and New Year\\\\u0027s when compared to light output during the rest of the year.\\\\n\\\\nThe next five maps (see also pages 161-163), created using data from the VIIRS DNB on the Suomi NPP satellite, show changes in lighting intensity and location around many major cities, comparing the nighttime light signals from December 2012 and beyond.\\\\n\\\\n---\\\\n\\\\n#### Figure 1. Location Overview\\\\n\\\\nA map of the western hemisphere with a marker indicating the mid-Atlantic region of the eastern United States, where the study of holiday lighting intensity was focused.\\\\n\\\\n---\\\\n\\\\n#### Figure 2. Holiday Lighting Intensity: Mid-Atlantic United States (2012\\\\u20132014)\\\\n\\\\nA map showing Maryland, New Jersey, Delaware, Virginia, West Virginia, Ohio, Kentucky, Tennessee, North Carolina, South Carolina, and surrounding areas. Major cities labeled include Washington, D.C., Richmond, Norfolk, and Raleigh.\\\\n\\\\nThe map uses colors to indicate changes in holiday nighttime lighting intensity between 2012 and 2014:\\\\n\\\\n- **Green/bright areas**: More holiday lighting (areas shining 20\\\\u201350% brighter in December).\\\\n- **Yellow areas**: No change in lighting.\\\\n- **Dim/grey areas**: Less holiday lighting.\\\\n\\\\nKey observations from the map:\\\\n\\\\n- The Washington, D.C. metropolitan area shows significant increases in lighting during the holidays, extending into Maryland and Virginia.\\\\n- Urban centers such as Richmond (Virginia), Norfolk (Virginia), Raleigh (North Carolina), and clusters in Tennessee and South Carolina also experience notable increases in light intensity during December.\\\\n- Rural areas and the interiors of West Virginia, Kentucky, and North Carolina show little change or less holiday lighting, corresponding to population density and urbanization.\\\\n\\\\n**Legend:**\\\\n\\\\n| Holiday Lighting Change | Color on Map   |\\\\n|------------------------|---------------|\\\\n| More                   | Green/bright  |\\\\n| No Change              | Yellow        |\\\\n| Less                   | Dim/grey      |\\\\n\\\\n_The scale bar indicates a distance of 100 km for reference._\\\\n\\\\n---\\\\n\\\\n\\\\u003C!-- PageFooter=\\\\u0022158 Earth at Night\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 174\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_152_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Power Outages\\\\n\\\\n## Rare Derecho Causes Power Outages\\\\u2014Washington, D.C.\\\\n\\\\n### Figure 1: Location of Derecho Impact\\\\n\\\\n*A globe showing the location of the Washington, D.C. metropolitan area (and surrounding region on the U.S. east coast), with a marker indicating the approximate impact zone of the June 29, 2012 derecho event.*\\\\n\\\\n---\\\\n\\\\nThese before-and-after images from the Suomi NPP VIIRS DNB show the severe impact that a rare, fast-moving thunderstorm system had on the Baltimore, Maryland\\\\u2013Washington, D.C. metropolitan area on June 29, 2012. The storm raced hundreds of miles from west of Chicago across Illinois, Indiana, Ohio, West Virginia, Virginia, Maryland, and Washington, D.C.; it combined intense lightning and rain with hurricane-force winds with speeds that were upwards of 60 miles (96 kilometers) per hour. It killed 22 people and caused some 4.3 million households to lose power for days.\\\\n\\\\n---\\\\n\\\\n### Figure 2: Nighttime Lights in the Baltimore\\\\u2013Washington Region Before the Storm\\\\n\\\\n#### Description of the Visual Information:\\\\n\\\\nThis night-time satellite image (from June 28, 2012) shows the Baltimore\\\\u2013Washington, D.C. region, extending west to Pittsburgh and south to Richmond. Major features labeled include:\\\\n\\\\n- Pittsburgh (upper left)\\\\n- Baltimore (top right)\\\\n- Washington, D.C. (central right)\\\\n- Richmond (lower right)\\\\n- Major highways: route 270, route 267, route 66 (all near Washington, D.C.)\\\\n- A scale indicator (50 km)\\\\n- North arrow for orientation\\\\n\\\\nBright clusters represent city lights, indicating areas of dense population and high electricity usage.\\\\n\\\\n**Verbalization of Content:**\\\\n\\\\n| City/Feature      | Nighttime Visible Lights?          | Location Relative to Region |\\\\n|-------------------|-----------------------------------|-----------------------------|\\\\n| Pittsburgh        | Yes (upper left, large cluster)    | Northwest                   |\\\\n| Baltimore         | Yes (bright cluster, upper right)  | Northeast                   |\\\\n| Washington, D.C.  | Yes (bright cluster, near center)  | Central/east-central        |\\\\n| Richmond          | Yes (bright cluster, bottom right) | South-southeast             |\\\\n| Route 270/267/66  | Associated clusters of lights      | Near Washington, D.C.       |\\\\n\\\\nBefore the derecho event, the region is characterized by extensive and continuous nighttime lighting tracing major highways and urban centers, particularly along the corridor from Baltimore through Washington, D.C., and toward Richmond.\\\\n\\\\n---\\\\n\\\\n*The subsequent image (not shown in this specific set) would reveal a marked reduction in nighttime lighting in the Baltimore\\\\u2013Washington, D.C. area, visualizing the extent of power outages caused by the storm.*\\\\n\\\\n---\\\\n\\\\n\\\\u003C!-- PageFooter=\\\\u0022136 Earth at Night\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 152\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_177_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Holiday Lights\\\\n\\\\n## Holiday Lighting in Florida (2012\\\\u20132014)\\\\n\\\\nThis figure presents a nighttime satellite map of Florida, highlighting changes in holiday lighting between 2012 and 2014. The map covers major urban areas including Jacksonville, Orlando, Tampa Bay, and Miami, with the Gulf of Mexico to the west.\\\\n\\\\nKey observations from the figure:\\\\n- The map displays areas of increased, decreased, or unchanged outdoor lighting intensity during the holiday season.\\\\n- Major metropolitan regions such as Miami, Tampa Bay, Orlando, and Jacksonville show noticeable concentrations of holiday lighting, with many surrounding areas experiencing changes in brightness compared to the non-holiday period.\\\\n- Color coding (not described in the image but referenced):  \\\\n  - **Less**: Areas where holiday lighting decreased  \\\\n  - **No change**: Areas where lighting remained stable  \\\\n  - **More**: Areas where holiday lighting increased\\\\n\\\\n**Legend:**\\\\n- The figure includes a scale bar indicating a span of 100 km for distance estimation.\\\\n- The map is oriented with north at the top.\\\\n\\\\n**Geographic Labels:**\\\\n- Jacksonville (northeast Florida)\\\\n- Orlando (central Florida)\\\\n- Tampa Bay (west-central Florida)\\\\n- Miami (southeast Florida)\\\\n- The Gulf of Mexico (to the west of the peninsula)\\\\n\\\\n**Takeaway:**\\\\nThe map visualizes spatial patterns in holiday lighting, indicating that urban and suburban areas in Florida experience substantial increases in nighttime brightness during the holiday period, particularly in and around major cities.\\\\n\\\\n\\\\u003C!-- PageNumber=\\\\u0022161\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 177\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_19_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"Dazzling photographs and images from space of our planet\\\\u0027s nightlights have captivated public attention for decades. In such images, patterns are immediately seen based on the presence or absence of light: a distinct coastline, bodies of water recognizable by their dark silhouettes, and the faint tendrils of roads and highways emanating from the brilliant blobs of light that are our modern, well-lit cities.\\\\n\\\\n### Figure: Earth\\\\u0027s Night Lights from Space\\\\n\\\\nThis image shows a view of the Earth from space at night. City lights illuminate the land, clearly delineating coastlines and urban areas, while the oceans remain in darkness. The bright patches indicate areas with concentrated human activity\\\\u2014major cities and road networks. In contrast, large dark areas signify sparsely populated or natural regions such as oceans or forests. The faint glow along some coasts highlights major cities near water bodies, and the transition from night to day can be seen along the planet\\\\u0027s curve (the terminator line). The background is filled with stars, framing Earth\\\\u0027s glowing edge against the depths of space.\\\\n\\\\n---\\\\n\\\\n\\\\u003C!-- PageNumber=\\\\u00223\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 19\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_153_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Power Outages\\\\n\\\\nA quick comparison between the June 28 and June 30 images reveals extensive power outages around Washington, D.C. and Baltimore. Clouds obscure the lights of Philadelphia and other areas north and east of Baltimore. Of particular interest is the loss of light to the north and west of Washington, D.C., along interstate highway Routes 270 and 66 and Maryland Route 267. Known as a \\\\u0022derecho,\\\\u0022 which is the Spanish word for \\\\u0022straight,\\\\u0022 the forceful winds can be as powerful as tornadoes, but the winds don\\\\u0027t twist\\\\u2014instead driving in a straight line over long distances; hence the name.\\\\n\\\\n---\\\\n\\\\n## Figure: Power Outages in the Mid-Atlantic Region (June 30, 2012)\\\\n\\\\nThis figure is a map of the Mid-Atlantic U.S., highlighting the metropolitan areas of Pittsburgh, Baltimore, Washington, D.C., and Richmond. Notable interstate routes (270, 267, and 66) are marked. The map shows city lights as seen from space at night. \\\\n\\\\n- **Observation:** On June 30, 2012, there are large areas of darkness present to the north and west of Washington, D.C. and around Baltimore, indicating power outages. Clouds obscure the lights to the northeast, particularly near Philadelphia.\\\\n- **Cities and Features Marked:** Pittsburgh (top left), Baltimore and Washington, D.C. (center right), Richmond (bottom center), and the routes 270, 267, and 66.\\\\n- **Scale:** The image includes a scale bar indicating 50 km for distance.\\\\n- **Cardinal Direction:** North is indicated.\\\\n\\\\n---\\\\n\\\\n**Description:**  \\\\nThe satellite image shows the impact of a derecho event that swept across the region, causing widespread loss of power evident by the large dark patches around and between Baltimore and Washington, D.C., especially along key highways. The event demonstrates how weather phenomena can lead to large-scale infrastructure disruptions.\\\\n\\\\n---\\\\n\\\\n\\\\u003C!-- PageNumber=\\\\u0022137\\\\u0022 --\\\\u003E\\\",\\r\\n  \\\"page_number\\\": 153\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_125_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Urban Development\\\\n\\\\n**Date:** October 1, 2013\\\\n\\\\n---\\\\n\\\\n## Figure: Urban Development and Infrastructure in the United States\\\\n\\\\nThis figure comprises two maps of the continental United States, highlighting the patterns of urban development and infrastructure.\\\\n\\\\n### Top Panel: Nighttime Lights Map (October 1, 2013)\\\\n\\\\nThis map displays the United States as seen from space at night on October 1, 2013. Major observations include:\\\\n\\\\n- A dense concentration of bright spots representing urban and suburban areas with prominent lighting, especially along the east coast, the Midwest (notably around Chicago), Texas, and California.\\\\n- The west and central parts of the country, such as the Rocky Mountains and deserts, appear much darker, indicating sparse population and fewer urban centers.\\\\n- The boundaries of the United States are outlined for reference.\\\\n- Major urban corridors are clearly visible, including the heavily lit regions running from Boston through New York City, Philadelphia, Baltimore, D.C., Atlanta, and further south, as well as the line of cities from Los Angeles through southern California.\\\\n\\\\n### Bottom Panel: Major Transport and River Networks\\\\n\\\\nThis map outlines the primary interstate highways, railroad lines, and major river systems in the continental United States, using different colors to distinguish among them:\\\\n\\\\n| Feature    | Color       | Description                                                                       |\\\\n|------------|-------------|-----------------------------------------------------------------------------------|\\\\n| Interstate | Red         | Key high-speed roadways, forming a vast national network and connecting cities     |\\\\n| Railroad   | Green       | Major rail lines paralleling some highway routes, providing freight and passenger service |\\\\n| River      | Blue        | Major river systems used historically for transport, industry, and urban siting    |\\\\n\\\\n- The locations of interstate highways closely follow the distribution of nighttime lights, as seen in the top panel.\\\\n- Railroad networks are especially dense in the Midwest and northeast, regions with both high population density and industrial activity.\\\\n- Major rivers, such as the Mississippi, Missouri, and Ohio, are marked in blue, reflecting their importance for historical urban development.\\\\n\\\\n**Scale:** Both maps include a scale bar representing 500 km and a North arrow for orientation.\\\\n\\\\n---\\\\n\\\\n**Summary:**  \\\\nThe figure visually demonstrates the relationship between urban development (as observed through nighttime satellite imagery) and the underlying networks of interstates, railroads, and rivers that have historically influenced the growth and connectivity of American cities. Most urbanized and densely lit areas correspond to nodes and crossroads within this transportation and river network.\\\\n\\\\n---\\\\n\\\\n**Page 109**\\\",\\r\\n  \\\"page_number\\\": 125\\r\\n}\\n\\nDocument Title: \\nDocument Content: {\\r\\n  \\\"id\\\": \\\"earth_at_night_508_page_112_verbalized\\\",\\r\\n  \\\"page_chunk\\\": \\\"# Urban Structure\\\\n\\\\n## The Winding Seine River and the City of Light - Paris, France\\\\n\\\\n**Location Context:**  \\\\nA simplified globe shows a marker at Paris, France in Western Europe, highlighting its geographic position in the northern part of the continent, near the western edge, in close proximity to the English Channel.\\\\n\\\\n---\\\\n\\\\nAround local midnight on April 8, 2015, astronauts onboard the ISS took this photograph of Paris, often referred to as the \\\\u0022City of Light.\\\\u0022 When viewed from low Earth orbit, the pattern of the street grid dominates the Parisian night, providing a completely different set of visual features from those visible during the day. For instance, the winding Seine River is a main visual cue by day, but here the thin black line of the river is hard to detect until you focus on the strong meanders and the streetlights on both banks.\\\\n\\\\nThe brightest boulevard in the dense network of streets is the Avenue des Champs-\\\\u00C9lys\\\\u00E9es, the historical axis of the city, as designed in the seventeenth century. This grand avenue joins the site of the former royal Palais des Tuileries\\\\u2014whose gardens appear as a dark rectangle on the river\\\\u2014to the star-like meeting place of eleven major boulevards at the Arc de Triomphe. This famous plaza is also referred to as the \\\\u00C9toile, or \\\\u0022star.\\\\u0022\\\\n\\\\nThe many forested parks of Paris stand out as black polygons\\\\u2014such as the Bois de Boulogne and Bois de Vincennes. The Bois de Boulogne is crisscrossed by a few roads and lighted paths.\\\\n\\\\nOrly airport is distinguished by very bright lights next to the dark areas or runways and surrounding open land. Paris\\\\u0027s great ring road, the Boulevard P\\\\u00E9riph\\\\u00E9rique, encloses the city center.\\\\n\\\\n---\\\\n\\\\n*Earth at Night*  \\\\nPage 96\\\",\\r\\n  \\\"page_number\\\": 112\\r\\n}\\n\",\n",
      "      \"status\": \"completed\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_30149933fda1983e00690b8ebf7fc48190a7e24ed2c0815b07\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Suburban belts display larger December brightening than urban cores, though urban cores have higher absolute light levels, because holiday lighting displays and related activities during Christmas and New Year's cause notably increased lighting intensity in suburban areas. This phenomenon has been observed in the United States, where nighttime lights shine 20 to 50 percent brighter in December compared to other months, with significant increases in lighting seen especially in suburban and residential areas around major metropolitan regions. Urban cores, already brightly lit year-round, show less relative increase because their baseline lighting levels are already high (Reference: earth_at_night_508_page_174_verbalized).\\n\\nThe Phoenix nighttime street grid is so sharply visible from space because the city is laid out along a regular grid of city blocks and streets, and street lighting highlights this pattern distinctly. The well-defined grid pattern of city blocks and thoroughfares such as the Grand Avenue, along with brightly lit commercial and industrial properties concentrated at intersections, contribute to the clarity of this grid from orbit. The urban grid infrastructure, combined with extensive surface streets and freeways in a sprawling metropolitan area composed of multiple municipalities, makes the street grid highly visible at night (Reference: earth_at_night_508_page_104_verbalized, earth_at_night_508_page_105_verbalized).\\n\\nIn contrast, large stretches of the interstate highways between Midwestern cities remain comparatively dim because these interstates are designed primarily for transportation rather than urban illumination, and the areas between cities tend to be less densely populated and less developed with fewer lighting sources. While the United States has an extensive transportation network, lighting on highways outside urban centers is typically less intense, leading to less visible illumination. Additionally, the development of new cities and suburbs along interstate highways in the twentieth century added light along some corridors, but the long distances of rural interstate highways between cities result in stretches that appear darker relative to highly lit urban street grids or city cores (Reference: earth_at_night_508_page_124_verbalized, earth_at_night_508_page_125_verbalized).\\n\\nThus, the combination of urban grid layout, lighting usage patterns, and population density explains why Phoenix's street grid is sharply visible from space, while many midwestern interstate highways appear dimmer.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"server_label\": \"knowledge-base\",\n",
      "      \"type\": \"mcp\",\n",
      "      \"allowed_tools\": [\n",
      "        \"knowledge_base_retrieve\"\n",
      "      ],\n",
      "      \"require_approval\": \"never\",\n",
      "      \"server_url\": \"https://magottei-s1m.search.windows.net/knowledgebases/earth-knowledge-base/mcp?api-version=2025-11-01-Preview\",\n",
      "      \"project_connection_id\": \"earthknowledgeconnection\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": {\n",
      "    \"id\": \"conv_30149933fda1983e00IibsaUyUeonheWWODhOhWn8eRVHt7jiU\"\n",
      "  },\n",
      "  \"reasoning\": {},\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 5577,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 512,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 6089\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"agent\": {\n",
      "    \"type\": \"agent_id\",\n",
      "    \"name\": \"earth-knowledge-agent\",\n",
      "    \"version\": \"23\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need the resources, be sure to delete them from your Azure subscription.  You can also delete individual objects to start over.\n",
    "\n",
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-search-agent' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_base(agent_name)\n",
    "print(f\"Knowledge base '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523474",
   "metadata": {},
   "source": [
    "### Delete the knowledge source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-at-night-ks' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_source(knowledge_source=knowledge_source_name) # This is new feature in 2025-08-01-Preview api version\n",
    "print(f\"Knowledge source '{knowledge_source_name}' deleted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ea545",
   "metadata": {},
   "source": [
    "### Delete the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9895f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
