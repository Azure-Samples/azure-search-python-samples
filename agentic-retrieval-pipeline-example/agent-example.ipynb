{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# Tutorial: Agentic retrieval using Azure AI Search and Foundry Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and Foundry Agent Service.\n",
    "\n",
    "In this notebook, you:\n",
    "\n",
    "1. Create and load an `earth-at-night` search index.\n",
    "\n",
    "1. Create an `earth-knowledge-source` that targets your index.\n",
    "\n",
    "1. Create an `earth-knowledge-base` that targets your knowledge source and an LLM for intelligent query planning.\n",
    "\n",
    "1. Use the knowledge base to fetch, rank, and synthesize relevant information from the index.\n",
    "\n",
    "1. Create an agent in Foundry Agent Service to determine when queries are needed.\n",
    "\n",
    "1. Create an MCP tool to orchestrate all requests.\n",
    "\n",
    "1. Start a chat with the agent.\n",
    "\n",
    "This notebook is referenced in [Tutorial: Build an end-to-end agentic retrieval solution using Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "Unlike [Quickstart: Use agentic retrieval in Azure AI Search](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval), this quickstart uses Foundry Agent Service to determine whether to retrieve data from the knowledge source and uses an MCP tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ An Azure AI Search service in any [region that provides agentic retrieval](https://learn.microsoft.com/azure/search/search-region-support).\n",
    "\n",
    "+ A [Microsoft Foundry project](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?view=foundry-classic&tabs=foundry) and resource. When you create a project, the resource is automatically created.\n",
    "\n",
    "+ A [supported LLM](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) deployed to your project. This notebook uses `gpt-5-mini`. We recommend a minimum token capacity of 100,000. You can find the LLM's capacity and rate limit in the Foundry portal. If you want vectorization at query time, you should also deploy a text embedding model.\n",
    "\n",
    "+ [Visual Studio Code](https://code.visualstudio.com/download) with the [Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python) and [Jupyter package](https://pypi.org/project/jupyter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2379a9",
   "metadata": {},
   "source": [
    "## Configure access\n",
    "\n",
    "This notebook assumes that you're using Microsoft Entra ID for authentication and role assignments for authorization.\n",
    "\n",
    "To configure role-based access:\n",
    "\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "1. On your Azure AI Search service:\n",
    "\n",
    "    1. [Enable role-based access](https://learn.microsoft.com/azure/search/search-security-enable-roles).\n",
    "    \n",
    "    1. [Create a system-assigned managed identity](https://learn.microsoft.com/azure/search/search-howto-managed-identities-data-sources#create-a-system-managed-identity).\n",
    "    \n",
    "    1. [Assign the following roles](https://learn.microsoft.com/azure/search/search-security-rbac#how-to-assign-roles-in-the-azure-portal) to yourself.\n",
    "    \n",
    "       + **Search Service Contributor**\n",
    "    \n",
    "       + **Search Index Data Contributor**\n",
    "    \n",
    "       + **Search Index Data Reader**\n",
    "\n",
    "    1. Assign **Search Index Data Reader** to your Microsoft Foundry project.\n",
    "\n",
    "1. On your Microsoft Foundry resource:\n",
    "\n",
    "    1. Assign the following roles to yourself.\n",
    "\n",
    "        + **Azure AI User**\n",
    "\n",
    "        + **Azure AI Project Manager**\n",
    "\n",
    "    1. Assign **Cognitive Services User** to the managed identity of your search service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "Save the `sample.env` file as `.env` and then modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI (for the models deployed to your project)\n",
    "+ Microsoft Foundry project\n",
    "\n",
    "You also need the resource ID of your project. You can find all of these values in the [Azure portal](https://portal.azure.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load connections\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.13.7.\n",
    "\n",
    "After your environment is created, load the environment variables to set up connections and object names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.core.tools import parse_resource_id\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "project_resource_id = os.environ[\"PROJECT_RESOURCE_ID\"]\n",
    "project_connection_name = os.getenv(\"PROJECT_CONNECTION_NAME\", \"earthknowledgeconnection\")\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "agent_name = os.getenv(\"AGENT_NAME\", \"earth-knowledge-agent\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "knowledge_source_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_SOURCE_NAME\", \"earth-knowledge-source\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth-at-night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "base_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-knowledge-base\")\n",
    "\n",
    "# Parse the resource ID to extract subscription and other components\n",
    "parsed_resource_id = parse_resource_id(project_resource_id)\n",
    "subscription_id = parsed_resource_id['subscription']\n",
    "resource_group = parsed_resource_id['resource_group']\n",
    "account_name = parsed_resource_id['name']\n",
    "project_name = parsed_resource_id['child_name_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create a search index\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use an existing index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schema requirement is a semantic configuration with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This notebook uses data from NASA's Earth at Night e-book. The data is retrieved from the [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data) repository on GitHub and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth-at-night'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2d9d5",
   "metadata": {},
   "source": [
    "## Create a knowledge source\n",
    "\n",
    "This step creates a knowledge source that targets the index you previously created. In the next step, you create a knowledge base that uses the knowledge source to orchestrate agentic retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf01881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndexKnowledgeSource, SearchIndexKnowledgeSourceParameters, SearchIndexFieldReference\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[SearchIndexFieldReference(name=\"id\"), SearchIndexFieldReference(name=\"page_number\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "print(f\"Knowledge source '{knowledge_source_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a knowledge base\n",
    "\n",
    "This step creates a knowledge base, which acts as a wrapper for your knowledge source and LLM deployment.\n",
    "\n",
    "`EXTRACTIVE_DATA` is the default modality and returns content from your knowledge sources without generative alteration. This is recommended for interaction with Foundry Agent Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base 'earth-knowledge-base' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeSourceReference, AzureOpenAIVectorizerParameters, KnowledgeRetrievalOutputMode, KnowledgeRetrievalMinimalReasoningEffort\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=knowledge_source_name\n",
    "        )\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base=knowledge_base)\n",
    "print(f\"Knowledge base '{base_name}' created or updated successfully\")\n",
    "\n",
    "mcp_endpoint = f\"{endpoint}/knowledgebases/{base_name}/mcp?api-version=2025-11-01-Preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an agent\n",
    "\n",
    "In Foundry Agent Service, an agent is a smart micro-service that can do RAG. The purpose of this agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "list(project_client.agents.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de7601",
   "metadata": {},
   "source": [
    "## Create an MCP tool connection\n",
    "\n",
    "In Microsoft Foundry, you must create a connection to authenticate to your MCP tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c209b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection 'earthknowledgeconnection' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
    "from azure.mgmt.cognitiveservices.models import ConnectionPropertiesV2BasicResource, CustomKeysConnectionProperties, CustomKeys\n",
    "import requests\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "# Requires the Foundry project to have Search Index Data Reader role on the search service\n",
    "bearer_token_provider = get_bearer_token_provider(credential, \"https://management.azure.com/.default\")\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token_provider()}\",\n",
    "}\n",
    "response = requests.put(\n",
    "    f\"https://management.azure.com{project_resource_id}/connections/{project_connection_name}?api-version=2025-10-01-preview\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        \"name\": project_connection_name,\n",
    "        \"type\": \"Microsoft.MachineLearningServices/workspaces/connections\",\n",
    "        \"properties\": {\n",
    "            \"authType\": \"ProjectManagedIdentity\",\n",
    "            \"category\": \"RemoteTool\",\n",
    "            \"target\": mcp_endpoint,\n",
    "            \"isSharedToAll\": True,\n",
    "            \"audience\": \"https://search.azure.com/\",\n",
    "            \"metadata\": { \"ApiType\": \"Azure\" }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response.raise_for_status()\n",
    "print(f\"Connection '{project_connection_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa363122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-knowledge-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "\n",
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Always provide references to the ID of the data source used to answer the question.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "mcp_kb_tool = MCPTool(\n",
    "    server_label=\"knowledge-base\",\n",
    "    server_url=mcp_endpoint,\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=project_connection_name\n",
    ")\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=agent_model,\n",
    "        instructions=instructions,\n",
    "        tools=[mcp_kb_tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2d5ed",
   "metadata": {},
   "source": [
    "## Start a chat with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9492c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The larger December brightening observed in suburban belts compared to urban cores, despite higher absolute light levels downtown, is primarily because suburban areas have more yard space and a prevalence of single-family homes where holiday light displays are more common and prominent. Urban cores do experience brightening during the holidays, but suburban areas show greater increases in lighting intensity due to more extensive holiday light decorations in residential yards and neighborhoods [source 4:4, page 176].\n",
      "\n",
      "Regarding the sharp visibility of Phoenix's nighttime street grid from space, the Phoenix metropolitan area is laid out along a regular grid of city blocks and streets, which is clearly visible at night due to street lighting. The sharp street grid pattern is emphasized by the extensive street lighting that traces the grid, and the presence of brightly lit transportation corridors (like Grand Avenue) and nodes such as shopping centers and gas stations at street intersections. Additionally, Phoenix's urban spread includes many suburban municipalities linked by well-illuminated surface streets and freeways, enhancing the visibility of the grid pattern from space [source 4:0 and 4:1, pages 104-105].\n",
      "\n",
      "In contrast, large stretches of interstate highways between Midwestern cities are comparatively dim at night because these transportation corridors often do not have extensive street-level lighting along the highways themselves, as lighting is typically limited to city areas and major intersections. While the interstates are well-traveled, fewer lights are installed directly on these long stretches of highway, making them less visible from space in nighttime imagery [source 4:3, page 124].\n",
      "\n",
      "Summary:\n",
      "- Suburban December brightening larger due to more holiday yard lighting in single-family homes and yards.\n",
      "- Phoenixâ€™s nighttime grid visibility is due to its regular urban street grid with comprehensive street lighting and connected suburban municipalities with illuminated streets.\n",
      "- Midwest interstate highways are dimmer because highways themselves are less illuminated between cities.\n",
      "\n",
      "References:  \n",
      "- Source 4:4 (page 176) for December brightening in suburban vs urban areas.  \n",
      "- Sources 4:0 and 4:1 (pages 104-105) for Phoenix nighttime grid visibility.  \n",
      "- Source 4:3 (page 124) for dimmer interstate stretches between Midwestern cities.\n"
     ]
    }
   ],
   "source": [
    "# Get the OpenAI client for responses and conversations\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "conversation = openai_client.conversations.create()\n",
    "\n",
    "# Send initial request that will trigger the MCP tool\n",
    "response = openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    input=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\",\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "print(f\"Response: {response.output_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b328340",
   "metadata": {},
   "source": [
    "## (Optional) Add remote SharePoint as a knowledge source\n",
    "\n",
    "Adding a remote SharePoint knowledge source requires an additional `x-ms-query-source-authorization` header in your MCP connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3711252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'remote-sharepoint' created or updated successfully.\n",
      "Knowledge base 'earth-knowledge-base' updated with new knowledge source successfully\n",
      "AI agent 'earth-knowledge-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import RemoteSharePointKnowledgeSource, KnowledgeSourceReference\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "remote_sp_ks = RemoteSharePointKnowledgeSource(\n",
    "    name=\"remote-sharepoint\",\n",
    "    description=\"SharePoint knowledge source\"\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=remote_sp_ks)\n",
    "print(f\"Knowledge source '{remote_sp_ks.name}' created or updated successfully.\")\n",
    "\n",
    "knowledge_base.knowledge_sources = [\n",
    "    KnowledgeSourceReference(name=remote_sp_ks.name), KnowledgeSourceReference(name=knowledge_source_name)\n",
    "]\n",
    "index_client.create_or_update_knowledge_base(knowledge_base=knowledge_base)\n",
    "print(f\"Knowledge base '{base_name}' updated with new knowledge source successfully\")\n",
    "\n",
    "mcp_kb_tool = MCPTool(\n",
    "    server_label=\"knowledge-base\",\n",
    "    server_url=mcp_endpoint,\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=project_connection_name,\n",
    "    headers={\n",
    "        \"x-ms-query-source-authorization\": get_bearer_token_provider(credential, \"https://search.azure.com/.default\")()\n",
    "    }\n",
    ")\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=agent_model,\n",
    "        instructions=instructions,\n",
    "        tools=[mcp_kb_tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need Azure AI Search or Microsoft Foundry, delete the resources from your Azure subscription. You can also start over by deleting individual objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395247f",
   "metadata": {},
   "source": [
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409befbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-knowledge-agent' version '4' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "project_client.agents.delete_version(agent.name, agent.version)\n",
    "print(f\"AI agent '{agent.name}' version '{agent.version}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e67115",
   "metadata": {},
   "source": [
    "### Delete the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base 'earth-knowledge-base' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_base(base_name)\n",
    "print(f\"Knowledge base '{base_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523474",
   "metadata": {},
   "source": [
    "### Delete the knowledge source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e35a6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_source(knowledge_source=knowledge_source_name) # This is new feature in 2025-08-01-Preview api version\n",
    "print(f\"Knowledge source '{knowledge_source_name}' deleted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ea545",
   "metadata": {},
   "source": [
    "### Delete the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9895f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
