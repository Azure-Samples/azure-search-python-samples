{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# Agentic retrieval using Azure AI Search and Azure AI Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and an Azure AI Agent.\n",
    "\n",
    "In this walkthrough, you will:\n",
    "\n",
    "+ Create an \"earth_at_night\" search index\n",
    "+ Load it with documents from a GitHub URL\n",
    "+ Create a knowledge agent on Azure AI Search that points to an LLM for intelligent query planning\n",
    "+ Create a Foundry agent in Azure AI Foundry to determine when queries are needed\n",
    "+ Create a Azure AI Agent tool (client) to orchestrate all requests\n",
    "+ Start a chat with the agent\n",
    "\n",
    "This notebook is referenced in [Build an agentic retrieval pipeline in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "This exercise differs from the [Agentic Retrieval Quickstart](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval) in how it uses Azure AI Agent to determine whether to retrieve data from the index, and how it uses an agent tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ Azure AI Search, basic tier or higher, in any region that supports semantic ranker.\n",
    "\n",
    "+ Azure OpenAI, and you should have an **Azure AI Developer** role assignment to create a Foundry project.\n",
    "\n",
    "+ An [Azure AI agent and Foundry project](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal), created in the Azure AI Foundry portal, with the basic setup, used for creating the Foundry agent.\n",
    "\n",
    "+ A deployment of a [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) in your Foundry project. This notebook uses gpt-4o-mini. We recommend 100,000 token capacity. You can find capacity and the rate limit in the model deployments list in the Azure AI Foundry portal.\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "Save the `sample.env` file as `.env` and then modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI\n",
    "+ Azure AI Foundry project\n",
    "\n",
    "You can find endpoints for Azure AI Search and Azure OpenAI in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You can find the project endpoint in the Azure AI Foundry portal:\n",
    "\n",
    "1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com) and open your project. \n",
    "\n",
    "1. In the **Overview** tile, find and copy the **Azure AI Foundry project endpoint**. \n",
    "\n",
    "   A hypothetical endpoint might look like this: `https://your-foundry-resource.services.ai.azure.com/api/projects/your-foundry-project`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load Connections\n",
    "\n",
    "Load the environment variables to set up connections and object names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth_at_night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-search-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create search index on Azure AI Search\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This sample uses data from NASA's Earth at Night e-book. It's retrieved from the sample data GitHub repository and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth_at_night'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a knowledge agent on Azure AI Search\n",
    "\n",
    "This steps creates a knowledge agent on Azure AI Search. This agent is a wrapper to a large language model, used for sending queries to an agentic retrieval pipeline. The maximum output size refers to the query response. Setting this value helps you control token usage and how many tokens are sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-search-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_gpt_deployment,\n",
    "                model_name=azure_openai_gpt_model\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,\n",
    "            default_reranker_threshold=2.5\n",
    "        )\n",
    "    ],\n",
    "    request_limits=KnowledgeAgentRequestLimits(\n",
    "        max_output_size=10000\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Knowledge agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an Azure AI Agent\n",
    "\n",
    "In the Azure AI Foundry, an agent is a smart micro-service that can do RAG. The purpose of this specific agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "list(project_client.agents.list_agents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa363122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-search-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer using the format [ref_id].\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=agent_model,\n",
    "    name=agent_name,\n",
    "    instructions=instructions\n",
    ")\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a051e",
   "metadata": {},
   "source": [
    "## Add an agentic retrieval tool to AI Agent\n",
    "\n",
    "An end-to-end pipeline needs an orchestration mechanism for coordinating calls to the retriever and agent. The pattern described in this notebook uses a [tool](https://learn.microsoft.com/azure/ai-services/agents/how-to/tools/function-calling) for this task. The tool calls the Azure AI Search knowledge retrieval client and the Azure AI agent, and it drives the conversations with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ee775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import FunctionTool, ToolSet, ListSortOrder\n",
    "\n",
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "thread = project_client.agents.threads.create()\n",
    "retrieval_results = {}\n",
    "\n",
    "def agentic_retrieval() -> str:\n",
    "    \"\"\"\n",
    "        Searches a NASA e-book about images of Earth at night and other science related facts.\n",
    "        The returned string is in a JSON format that contains the reference id.\n",
    "        Be sure to use the same format in your agent's response\n",
    "        You must refer to references by id number\n",
    "    \"\"\"\n",
    "    # Take the last 5 messages in the conversation\n",
    "    messages = project_client.agents.messages.list(thread.id, limit=5, order=ListSortOrder.DESCENDING)\n",
    "    # Reverse the order so the most recent message is last\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    retrieval_result = agent_client.retrieve(\n",
    "        retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "            messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg.content[0].text)]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "            target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Associate the retrieval results with the last message in the conversation\n",
    "    last_message = messages[-1]\n",
    "    retrieval_results[last_message.id] = retrieval_result\n",
    "\n",
    "    # Return the grounding response to the agent\n",
    "    return retrieval_result.response[0].content[0].text\n",
    "\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling\n",
    "functions = FunctionTool({ agentic_retrieval })\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "project_client.agents.enable_auto_function_calls(toolset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5b621",
   "metadata": {},
   "source": [
    "## Start a chat with the agent\n",
    "\n",
    "During the chat, you use the standard Azure AI agent tool calling APIs.  We send the message with questions, and the agent decides when to retrieve knowledge from your search index using agentic retrieval.\n",
    "\n",
    "The remaining cells take a closer look at output and show how to add another turn to the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent response: Suburban belts display larger December brightening than urban cores due to differences in light sources and usage patterns\n",
      " Suburban lighting is often concentrated in residential and commercial areas with extensive decorative lighting during the holiday season, leading to larger seasonal brightening\n",
      " Urban cores, despite higher absolute light levels, may have a more consistent year-round light profile due to steady illumination from offices, industrial areas, and traffic systems [ref_id: 1]\n",
      "\n",
      "\n",
      "The Phoenix nighttime street grid is sharply visible from space because the city is designed along a regular grid of street blocks, a characteristic of western U\n",
      "S\n",
      " urban planning\n",
      " This grid, combined with widespread automobile use, results in extensive street lighting that defines the layout of the city vividly at night\n",
      " In contrast, large stretches of midwestern interstates between cities remain comparatively dim because highways typically lack dense lighting infrastructure and are less populated compared to urban areas where lighting clusters around streets, intersections, and residential zones [ref_id: 0][ref_id: 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import AgentsNamedToolChoice, AgentsNamedToolChoiceType, FunctionName\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,\n",
    "    agent_id=agent.id,\n",
    "    tool_choice=AgentsNamedToolChoice(type=AgentsNamedToolChoiceType.FUNCTION, function=FunctionName(name=\"agentic_retrieval\")),\n",
    "    toolset=toolset)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "output = project_client.agents.messages.get_last_message_text_by_role(thread_id=thread.id, role=\"assistant\").text.value\n",
    "\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88be35",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n",
    "\n",
    "Each retrieval response from Azure AI Search includes the unified string (grounding data from search search results), the query plan, and  reference data showing which chunks of source document contributed content to the unified string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval activity\n",
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"type\": \"ModelQueryPlanning\",\n",
      "    \"input_tokens\": 1265,\n",
      "    \"output_tokens\": 322\n",
      "  },\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"December brightening in suburban belts vs urban cores\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:00:25.483Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 697\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"Visibility of Phoenix nighttime street grid from space\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:00:25.812Z\",\n",
      "    \"count\": 2,\n",
      "    \"elapsed_ms\": 315\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"Dimness of midwestern interstate stretches at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:00:26.165Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 351\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"type\": \"AzureSearchSemanticRanker\",\n",
      "    \"input_tokens\": 78294\n",
      "  }\n",
      "]\n",
      "Retrieval results\n",
      "[\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"1\",\n",
      "    \"activity_source\": 2,\n",
      "    \"doc_key\": \"earth_at_night_508_page_104_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"0\",\n",
      "    \"activity_source\": 2,\n",
      "    \"doc_key\": \"earth_at_night_508_page_105_verbalized\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "retrieval_result = retrieval_results.get(message.id)\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bfb9f",
   "metadata": {},
   "source": [
    "## Continue the conversation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9478191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent response: To find lava at night, you can rely on satellite imagery that captures the glow from active lava flows\n",
      " Instruments like the VIIRS Day/Night Band (DNB) can detect thermal and infrared emissions from lava, even in low-light conditions\n",
      " Satellite systems such as Landsat 8 use thermal and infrared bands to distinguish between hot lava, cooling lava, and flows obscured by cloud cover\n",
      " This capability has been utilized to monitor volcanic activity at locations like Mount Etna (Sicily, Italy) and Kilauea (Hawaii), providing critical data for hazard assessment and emergency management [ref_id: 1][ref_id: 3][ref_id: 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How do I find lava at night? Use the retrieval tool to answer this question.\"\n",
    ")\n",
    "\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,\n",
    "    agent_id=agent.id,\n",
    "    tool_choice=AgentsNamedToolChoice(type=AgentsNamedToolChoiceType.FUNCTION, function=FunctionName(name=\"agentic_retrieval\")),\n",
    "    toolset=toolset)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "output = project_client.agents.messages.get_last_message_text_by_role(thread_id=thread.id, role=\"assistant\").text.value\n",
    "\n",
    "\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366ed37",
   "metadata": {},
   "source": [
    "## Review retrieval activity and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval activity\n",
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"type\": \"ModelQueryPlanning\",\n",
      "    \"input_tokens\": 1495,\n",
      "    \"output_tokens\": 319\n",
      "  },\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"how to locate lava flows at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:01:14.742Z\",\n",
      "    \"count\": 6,\n",
      "    \"elapsed_ms\": 416\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"best tools for finding lava at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:01:15.101Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 346\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"type\": \"AzureSearchQuery\",\n",
      "    \"target_index\": \"earth_at_night\",\n",
      "    \"query\": {\n",
      "      \"search\": \"safety tips for finding lava at night\"\n",
      "    },\n",
      "    \"query_time\": \"2025-05-20T17:01:15.538Z\",\n",
      "    \"count\": 0,\n",
      "    \"elapsed_ms\": 436\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"type\": \"AzureSearchSemanticRanker\",\n",
      "    \"input_tokens\": 71809\n",
      "  }\n",
      "]\n",
      "Retrieval results\n",
      "[\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"5\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_60_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"4\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_64_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"3\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_46_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"2\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_66_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"1\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_65_verbalized\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"AzureSearchDoc\",\n",
      "    \"id\": \"0\",\n",
      "    \"activity_source\": 1,\n",
      "    \"doc_key\": \"earth_at_night_508_page_44_verbalized\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "retrieval_result = retrieval_results.get(message.id)\n",
    "if retrieval_result is None:\n",
    "    raise RuntimeError(f\"No retrieval results found for message {message.id}\")\n",
    "\n",
    "print(\"Retrieval activity\")\n",
    "print(json.dumps([activity.as_dict() for activity in retrieval_result.activity], indent=2))\n",
    "print(\"Retrieval results\")\n",
    "print(json.dumps([reference.as_dict() for reference in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04661708",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need the resources, be sure to delete them from your Azure subscription.  You can also delete individual objects to start over.\n",
    "\n",
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-search-agent' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_agent(agent_name)\n",
    "print(f\"Knowledge agent '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ea545",
   "metadata": {},
   "source": [
    "### Delete the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9895f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
