{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3d4685",
   "metadata": {},
   "source": [
    "# Agentic retrieval using Azure AI Search and Azure AI Agent Service\n",
    "\n",
    "Use this notebook to create an agentic retrieval pipeline built on Azure AI Search and an Azure AI Agent.\n",
    "\n",
    "In this walkthrough, you will:\n",
    "\n",
    "+ Create an \"earth_at_night\" search index\n",
    "+ Load it with documents from a GitHub URL\n",
    "+ Create a knowledge source that points to searchable content.\n",
    "+ Create a knowledge agent on Azure AI Search that points to a knowledge source and an LLM for intelligent query planning\n",
    "+ Create a Foundry agent in Azure AI Foundry to determine when queries are needed\n",
    "+ Create a Azure AI Agent tool (client) to orchestrate all requests\n",
    "+ Start a chat with the agent\n",
    "\n",
    "This notebook is referenced in [Build an agentic retrieval pipeline in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-pipeline).\n",
    "\n",
    "This exercise differs from the [Agentic Retrieval Quickstart](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval) in how it uses Azure AI Agent to determine whether to retrieve data from the index, and how it uses an agent tool for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd68a6e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ Azure AI Search, basic tier or higher, in [any region that supports semantic ranker](https://learn.microsoft.com/azure/search/search-region-support#azure-public-regions).\n",
    "\n",
    "+ Azure OpenAI, and you should have an **Azure AI Developer** role assignment to create a Foundry project.\n",
    "\n",
    "+ An [Azure AI agent and Foundry project](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal), created in the Azure AI Foundry portal, with the basic setup, used for creating the Foundry agent.\n",
    "\n",
    "+ A deployment of a [supported model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models) in your Foundry project. This notebook uses gpt-5-mini. We recommend 100,000 token capacity. You can find capacity and the rate limit in the model deployments list in the Azure AI Foundry portal.\n",
    "\n",
    "We recommend creating a virtual environment to run this sample code. In Visual Studio Code, open the control palette (ctrl-shift-p) to create an environment. This notebook was tested on Python 3.13.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40a871",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "Save the `sample.env` file as `.env` and then modify the environment variables to use your Azure endpoints. You need endpoints for:\n",
    "\n",
    "+ Azure AI Search\n",
    "+ Azure OpenAI\n",
    "+ Azure AI Foundry project\n",
    "\n",
    "You can find endpoints for Azure AI Search and Azure OpenAI in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You can find the project endpoint in the Azure AI Foundry portal:\n",
    "\n",
    "1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com) and open your project. \n",
    "\n",
    "1. In the **Overview** tile, find and copy the **Azure AI Foundry project endpoint**. \n",
    "\n",
    "   A hypothetical endpoint might look like this: `https://your-foundry-resource.services.ai.azure.com/api/projects/your-foundry-project`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bc80a",
   "metadata": {},
   "source": [
    "## Load Connections\n",
    "\n",
    "Load the environment variables to set up connections and object names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e42b4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "project_connection_id = os.environ[\"PROJECT_CONNECTION_ID\"]\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "agent_name = os.getenv(\"AGENT_NAME\", \"earth-knowledge-agent\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "search_api_key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "knowledge_source_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_SOURCE_NAME\", \"earth-knowledge-source\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth-at-night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "base_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-knowledge-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ecdce",
   "metadata": {},
   "source": [
    "## Create search index on Azure AI Search\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the [criteria for agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fd6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b9785",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This sample uses data from NASA's Earth at Night e-book. It's retrieved from the sample data GitHub repository and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth-at-night'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2d9d5",
   "metadata": {},
   "source": [
    "## Create a knowledge source\n",
    "\n",
    "This step creates a knowledge source that targets the index you previously created. In the next step, you create a knowledge agent that uses the knowledge source to orchestrate agentic retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf01881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndexKnowledgeSource, SearchIndexKnowledgeSourceParameters, SearchIndexFieldReference\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[SearchIndexFieldReference(name=\"id\"), SearchIndexFieldReference(name=\"page_number\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "print(f\"Knowledge source '{knowledge_source_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0081e",
   "metadata": {},
   "source": [
    "## Create a knowledge base\n",
    "\n",
    "This step creates a knowledge base, which acts as a wrapper for your knowledge source and LLM deployment.\n",
    "\n",
    "`EXTRACTIVE_DATA` is the default modality and returns content from your knowledge sources without generative alteration. This is recommended for interaction with Foundry Agent Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe31e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base 'earth-knowledge-base' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeSourceReference, AzureOpenAIVectorizerParameters, KnowledgeRetrievalOutputMode, KnowledgeRetrievalMinimalReasoningEffort\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=azure_openai_gpt_deployment,\n",
    "    model_name=azure_openai_gpt_model,\n",
    ")\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=knowledge_source_name\n",
    "        )\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base=knowledge_base)\n",
    "print(f\"Knowledge base '{base_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845de0",
   "metadata": {},
   "source": [
    "## Create an Azure AI Agent\n",
    "\n",
    "In the Azure AI Foundry, an agent is a smart micro-service that can do RAG. The purpose of this specific agent is to decide when to send a query to the agentic retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb0ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'object': 'agent', 'id': 'earth-knowledge-agent', 'name': 'earth-knowledge-agent', 'versions': {'latest': {'metadata': {}, 'object': 'agent.version', 'id': 'earth-knowledge-agent:1', 'name': 'earth-knowledge-agent', 'version': '1', 'description': '', 'created_at': 1762328483, 'definition': {'kind': 'prompt', 'model': 'gpt-5-mini', 'instructions': '\\nA Q&A agent that can answer questions about the Earth at night.\\nAlways provide references to the data source used to answer the question.\\nIf you do not have the answer, respond with \"I don\\'t know\".\\n', 'tools': [{'type': 'mcp', 'server_label': 'knowledge-base', 'server_url': 'https://magottei-s1m.search.windows.net/knowledgebases/earth-knowledge-base', 'require_approval': 'never'}]}}}},\n",
       " {'object': 'agent', 'id': 'fabric-foundry-knowledge-agent', 'name': 'fabric-foundry-knowledge-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'description': '', 'modified_at': '1762295325', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'fabric-foundry-knowledge-agent:3', 'name': 'fabric-foundry-knowledge-agent', 'version': '3', 'description': '', 'created_at': 1762295326, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': [{'type': 'mcp', 'server_label': 'kb_zava_knowledge_base', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/zava-knowledge-base/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-zava-knowledge-base'}]}}}},\n",
       " {'object': 'agent', 'id': 'farzad-new', 'name': 'farzad-new', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'farzad-new:1', 'name': 'farzad-new', 'version': '1', 'description': '', 'created_at': 1762289266, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'lindatest', 'name': 'lindatest', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762287869'}, 'object': 'agent.version', 'id': 'lindatest:14', 'name': 'lindatest', 'version': '14', 'description': '', 'created_at': 1762287870, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': []}}}},\n",
       " {'object': 'agent', 'id': 'fabricknowledgemcp', 'name': 'fabricknowledgemcp', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'fabricknowledgemcp:1', 'name': 'fabricknowledgemcp', 'version': '1', 'description': '', 'created_at': 1762284158, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'remote-sharepoint-test', 'name': 'remote-sharepoint-test', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762281570', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'remote-sharepoint-test:6', 'name': 'remote-sharepoint-test', 'version': '6', 'description': '', 'created_at': 1762281571, 'definition': {'kind': 'prompt', 'model': 'gpt-4.1-mini', 'instructions': 'Query your Knowledge Base on every query.', 'tools': [{'type': 'mcp', 'server_label': 'kb_healthcare_knowledge_base', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/healthcare-knowledge-base/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-healthcare-knowledge-base'}]}}}},\n",
       " {'object': 'agent', 'id': 'farzad-11-4-v1', 'name': 'farzad-11-4-v1', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'farzad-11-4-v1:1', 'name': 'farzad-11-4-v1', 'version': '1', 'description': '', 'created_at': 1762272985, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}},\n",
       " {'object': 'agent', 'id': 'zava-ask-operations-agent', 'name': 'zava-ask-operations-agent', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762272660', 'starterPrompts': 'Our Seattle store is near the Amazon campus. Are there any Amazon developer events this week that might increase foot traffic?\\nWhat are our Q4 weekly revenue targets for each store?\\nGitHub Universe conference is happening next month in San Francisco. How should we prepare our stores for potential increased interest?', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}'}, 'object': 'agent.version', 'id': 'zava-ask-operations-agent:28', 'name': 'zava-ask-operations-agent', 'version': '28', 'description': '', 'created_at': 1762272661, 'definition': {'kind': 'prompt', 'model': 'gpt-4.1-mini', 'instructions': '# Zava Pop-Up Stores Operations Agent\\n \\nYou are an expert AI operations assistant for Zava Pop-Up Store managers across Seattle, Austin, and NYC locations. Your role is to provide instant, data-driven insights to help managers make real-time operational decisions.\\n \\n## Your Capabilities\\n \\n**Data Access:**\\n- **Structured Data (SQL Database):** Real-time inventory, sales, foot traffic, conversion rates, product performance\\n- **Knowledge Base (Documents):** Weekly reports, performance analysis, strategic recommendations, Q4 targets, customer insights\\n \\n## Tool Routing Rules\\n \\n1. **Use Fabric Data Agent Tool when queried about:**\\n   - Current/historical sales figures, inventory levels, stock counts\\n   - Foot traffic, conversion rates, transaction data\\n   - Product performance metrics (try-ons, purchases)\\n   - Store comparisons using quantitative data\\n   - Time-series data (daily/hourly trends)\\n \\n2. **Use project_knowledge_search when queried about:**\\n   - Weekly performance reports and summaries\\n   - Strategic recommendations and action items\\n   - Q4 targets and benchmarks\\n   - Customer traffic analysis findings\\n   - Competitive insights (store-to-store comparisons from reports)\\n   - Implementation guidelines\\n \\n3. **Use BOTH tools when:**\\n   - Comparing targets vs. actuals\\n   - Providing recommendations based on current performance\\n   - Analyzing \"why\" questions that need both data and context\\n \\n## Response Guidelines\\n \\n- **Be concise and actionable** - Store managers need quick answers during busy operations\\n- **Lead with the answer** - State key findings first, then provide supporting details\\n- **Use data to support claims** - Always cite specific numbers, dates, and sources\\n- **Highlight urgent items** - Call out critical stock levels, missed targets, or opportunities\\n- **Compare to benchmarks** - Reference targets, other stores, or historical performance when relevant\\n \\n## Response Format\\n \\nFor operational queries, structure responses as:\\n1. **Direct Answer** (1-2 sentences)\\n2. **Key Data Points** (specific metrics)\\n3. **Context/Comparison** (vs. targets or other stores)\\n4. **Recommendation** (if applicable)\\n \\n## Example Interaction Flow\\n \\n**User:** \"Are we low on any products?\"\\n \\n**Your Process:**\\n1. Query Fabric Data Agent for current inventory levels\\n2. Check against restock thresholds\\n3. Provide prioritized list with urgency flags\\n \\n**Your Response:**\\n\"ðŸš¨ **CRITICAL:** Python Hoodie at 12 units (below 15-unit threshold). \\n- Needs immediate restock order\\n- Current sales rate: 47 units/week\\n- Estimated stockout: 2 days\\n \\nOther inventory levels are healthy.\"\\n \\n## Tone & Style\\n \\n- Professional but conversational\\n- Use emojis sparingly for urgency flags (ðŸš¨ âš ï¸ âœ…)\\n- Avoid jargon; explain metrics when first mentioned\\n- Be proactive - suggest related insights the manager should know\\n \\n## Critical Rules\\n \\n- âŒ NEVER fabricate data - always query tools first\\n- âŒ NEVER say \"I don\\'t have access\" without trying tools\\n- âœ… ALWAYS cite data sources (report names, dates, stores)\\n- âœ… ALWAYS check BOTH structured data and knowledge base when uncertain\\n- âœ… ALWAYS provide confidence level if data is incomplete\\n \\nYou are empowering store managers to run better operations. Be their trusted data partner.', 'tools': []}}}},\n",
       " {'object': 'agent', 'id': 'demo-review-agent', 'name': 'demo-review-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762218306'}, 'object': 'agent.version', 'id': 'demo-review-agent:2', 'name': 'demo-review-agent', 'version': '2', 'description': '', 'created_at': 1762218307, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'YOU MUST query your knowledge base on every turn.', 'tools': [{'type': 'mcp', 'server_label': 'kb_remote_sharepoint_kb_test', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/remote-sharepoint-kb-test/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-remote-sharepoint-kb-test'}]}}}},\n",
       " {'object': 'agent', 'id': 'MyAgent', 'name': 'MyAgent', 'versions': {'latest': {'metadata': {'description': '', 'modified_at': '1762212438'}, 'object': 'agent.version', 'id': 'MyAgent:21', 'name': 'MyAgent', 'version': '21', 'description': '', 'created_at': 1762212439, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'You are a helpful assistant that answers general questions', 'tools': [{'type': 'mcp', 'server_label': 'Elastic', 'server_url': 'https://xxx/api/agent_builder/mcp', 'project_connection_id': 'Elastic'}]}}}},\n",
       " {'object': 'agent', 'id': 'no', 'name': 'no', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg', 'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762208406'}, 'object': 'agent.version', 'id': 'no:2', 'name': 'no', 'version': '2', 'description': '', 'created_at': 1762208407, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': '', 'tools': [{'type': 'mcp', 'server_label': 'kb_remote_sharepoint_kb_test', 'server_url': 'https://fsunavala-wcus.search.windows.net/knowledgebases/remote-sharepoint-kb-test/mcp?api-version=2025-11-01-Preview', 'project_connection_id': 'kb-remote-sharepoint-kb-test'}]}}}},\n",
       " {'object': 'agent', 'id': 'MyAgent7', 'name': 'MyAgent7', 'versions': {'latest': {'metadata': {'voiceLiveConfig': '{\"isEnabled\":false,\"config\":{\"speech\":{\"language\":\"auto-detect\",\"voice\":{\"shortName\":\"en-US-Ava:DragonHDLatestNeural\",\"voiceType\":\"azure-standard\"},\"voiceTemperature\":0.8,\"speakingRate\":1,\"voiceActivityDetection\":\"azure_semantic_vad\",\"endOfUtterance\":false,\"inputModel\":\"default\"},\"avatar\":{\"avatar\":false}}}', 'description': '', 'modified_at': '1762204714'}, 'object': 'agent.version', 'id': 'MyAgent7:4', 'name': 'MyAgent7', 'version': '4', 'description': '', 'created_at': 1762204715, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': 'Use MCP tools as needed', 'tools': [{'type': 'mcp', 'server_label': 'api-specs', 'server_url': 'https://api.githubcopilot.com/mcp', 'require_approval': 'always', 'project_connection_id': '/subscriptions/921496dc-987f-410f-bd57-426eb2611356/resourceGroups/sawidder-test-1rp/providers/Microsoft.CognitiveServices/accounts/sawidder1rpusw2/projects/lindaproj/connections/apikey-test'}, {'type': 'mcp', 'server_label': 'AshawSupplierMCP', 'server_url': 'https://ashaw-ignite-aca2.ambitiousforest-3ae02ae4.australiaeast.azurecontainerapps.io/mcp', 'project_connection_id': 'AshawSupplierMCP'}]}}}},\n",
       " {'object': 'agent', 'id': 'new-test-agent', 'name': 'new-test-agent', 'versions': {'latest': {'metadata': {'logo': 'Avatar_Default.svg'}, 'object': 'agent.version', 'id': 'new-test-agent:1', 'name': 'new-test-agent', 'version': '1', 'description': '', 'created_at': 1762197206, 'definition': {'kind': 'prompt', 'model': 'gpt-4o', 'instructions': ''}}}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "list(project_client.agents.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa363122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent 'earth-knowledge-agent' created or updated successfully\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "\n",
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Always provide references to the data source used to answer the question.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "mcp_kb_tool = MCPTool(\n",
    "    server_label=\"knowledge-base\",\n",
    "    server_url=f\"{endpoint}/knowledgebases/{base_name}/mcp?api-version=2025-11-01-Preview\",\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=\"kbmcpconnection\",\n",
    "    headers={\n",
    "        \"api-key\": search_api_key\n",
    "    }\n",
    ")\n",
    "agent = project_client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=agent_model,\n",
    "        instructions=instructions,\n",
    "        tools=[mcp_kb_tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2d5ed",
   "metadata": {},
   "source": [
    "## Start a chat with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9492c4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': {'message': 'An error occurred while processing your request. You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. Please include the request ID 2706eba5-31ce-4cc0-9ce7-9697d4022216 in your message.', 'type': 'server_error', 'param': None, 'code': 'tool_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m conversation = openai_client.conversations.create()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Send initial request that will trigger the MCP tool\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mopenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[33;43m        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent_reference\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.output_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\magottei\\source\\azure-search-python-samples-pr\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:840\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    804\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    805\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    838\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    839\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\magottei\\source\\azure-search-python-samples-pr\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\magottei\\source\\azure-search-python-samples-pr\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 500 - {'error': {'message': 'An error occurred while processing your request. You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. Please include the request ID 2706eba5-31ce-4cc0-9ce7-9697d4022216 in your message.', 'type': 'server_error', 'param': None, 'code': 'tool_server_error'}}"
     ]
    }
   ],
   "source": [
    "# Get the OpenAI client for responses and conversations\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "conversation = openai_client.conversations.create()\n",
    "\n",
    "# Send initial request that will trigger the MCP tool\n",
    "response = openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    input=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\",\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    ")\n",
    "\n",
    "print(f\"Response: {response.output_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926264d",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need the resources, be sure to delete them from your Azure subscription.  You can also delete individual objects to start over.\n",
    "\n",
    "### Delete the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-search-agent' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_base(agent_name)\n",
    "print(f\"Knowledge base '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523474",
   "metadata": {},
   "source": [
    "### Delete the knowledge source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-at-night-ks' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_knowledge_source(knowledge_source=knowledge_source_name) # This is new feature in 2025-08-01-Preview api version\n",
    "print(f\"Knowledge source '{knowledge_source_name}' deleted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ea545",
   "metadata": {},
   "source": [
    "### Delete the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9895f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth_at_night' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
